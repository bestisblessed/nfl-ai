{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ec3ee-e002-4004-acc7-6a8f7974e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c908d3-691c-4452-9439-d208048ef068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_to_american_odds(prob):\n",
    "    epsilon = 1e-10\n",
    "    prob = max(min(prob, 1 - epsilon), epsilon)\n",
    "    if prob > 0.5:\n",
    "        return -100 * (prob / (1 - prob))\n",
    "    else:\n",
    "        return 100 * ((1 - prob) / prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0904f3-02f8-4946-891f-6068f326e296",
   "metadata": {},
   "source": [
    "# Starting Features\n",
    "\n",
    "1. Rushing/Receiving Yards\n",
    "2. Touchdowns Scored Average (Historical) \n",
    "3. Opponent Defense Rating\n",
    "4. Team Offensive Rank\n",
    "5. Matchup-Specific Metrics (e.g., Historical Performance Against Specific Opponent)\n",
    "6. Weather Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18034db9-6ea3-42a6-84ec-9056a3169d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Skeleton Code\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the data\n",
    "X = df[['rushing_receiving_yards', 'tds_scored_avg', 'opponent_defense_rating', \n",
    "        'team_offensive_rank', 'historical_vs_opponent', 'weather_conditions']]\n",
    "y = df['touchdown']  # Binary target variable (1 for touchdown, 0 otherwise)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss', \n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea09e1-7c3b-4eba-bfb3-d6f2404e9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Skeleton Code\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the data\n",
    "X = df[['rushing_receiving_yards', 'tds_scored_avg', 'opponent_defense_rating', \n",
    "        'team_offensive_rank', 'historical_vs_opponent', 'weather_conditions']]\n",
    "y = df['touchdown']  # Binary target variable (1 for touchdown, 0 otherwise)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf9c13-2b3a-43a4-828e-379c65d37679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0032a4b-eded-47de-943e-0b81801745d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ccb0d-a635-4a4b-8c36-1d76226b3da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f4c08-3636-409d-a90d-fbb88a19f483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b475d-ebdd-473c-a5f1-1ba325f7ea6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebf395-5645-4bed-9047-faff74627573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eea007-993c-42be-8f33-16955f6e547e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b79c6d-72c2-4fba-8aff-91d388380ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac8fdf87-3776-45ec-9701-49fc51d62596",
   "metadata": {},
   "source": [
    "Here's a basic skeleton code for each of the three recommended models: XGBoost, LightGBM, and Random Forest. These examples assume you're using Python with common machine learning libraries such as `scikit-learn`, `xgboost`, and `lightgbm`.\n",
    "\n",
    "### 1. **XGBoost**\n",
    "```python\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X and y are your features and target variables from nfl.db\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss', \n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "```\n",
    "\n",
    "### 2. **LightGBM**\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X and y are your features and target variables from nfl.db\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the LightGBM model\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary', \n",
    "    metric='binary_logloss'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "```\n",
    "\n",
    "### 3. **Random Forest**\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X and y are your features and target variables from nfl.db\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "```\n",
    "\n",
    "### Key Points\n",
    "- **Data Preparation:** These examples assume that you have already prepared your feature matrix `X` and target vector `y`.\n",
    "- **Model Initialization:** Each model is initialized with basic parameters. You can tune these parameters to improve performance based on your specific data.\n",
    "- **Training:** The models are trained using the `fit` method on the training data.\n",
    "- **Prediction:** Predictions are made on the test data, and the accuracy is calculated as a basic performance metric. Depending on your needs, you might want to use other metrics like AUC-ROC, precision, recall, or F1-score.\n",
    "- **Evaluation:** The accuracy is printed as a simple measure of performance.\n",
    "\n",
    "You can further enhance these skeleton codes by adding data preprocessing steps, feature selection, cross-validation, hyperparameter tuning, and more depending on the complexity of your task and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1f277-1148-4b6d-8ae1-48611c07efb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7096883-3f41-4f2b-9173-c2c52d5e7590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d95fc-6b77-491c-ba85-9788e62c39c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
