{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f758ee38-31e4-474c-9276-ec60449c11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8e9dc5-e07d-4bd4-95bb-e499244f0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ../Scrapers/data/* data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d4c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da4d1ef2-0f07-49b5-bd23-f6aa6a744f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            player team pass_cmp pass_att pass_yds pass_td pass_int  \\\n",
      "0      Zay Flowers  BAL     None     None     None    None     None   \n",
      "2   Rashod Bateman  BAL     None     None     None    None     None   \n",
      "6   Nelson Agholor  BAL     None     None     None    None     None   \n",
      "16   Xavier Worthy   KC     None     None     None    None     None   \n",
      "17     Rashee Rice   KC     None     None     None    None     None   \n",
      "\n",
      "   pass_sacked pass_sacked_yds pass_long  ...   rec rec_yds rec_td rec_long  \\\n",
      "0         None            None      None  ...  None    None   None     None   \n",
      "2         None            None      None  ...  None    None   None     None   \n",
      "6         None            None      None  ...  None    None   None     None   \n",
      "16        None            None      None  ...  None    None   None     None   \n",
      "17        None            None      None  ...  None    None   None     None   \n",
      "\n",
      "   fumbles fumbles_lost          game_id opponent_team  home position  \n",
      "0     None         None  2024_02_BUF_MIA          None  None       WR  \n",
      "2     None         None  2024_02_BUF_MIA          None  None       WR  \n",
      "6     None         None  2024_02_BUF_MIA          None  None       WR  \n",
      "16    None         None  2024_02_BUF_MIA          None  None       WR  \n",
      "17    None         None  2024_02_BUF_MIA          None  None       WR  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Making empty rows for upcoming games test set\n",
    "\n",
    "# Load your data\n",
    "file_path = 'data/all_passing_rushing_receiving.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get the list of upcoming game_ids\n",
    "upcoming_game_ids = [\n",
    "    \"2024_02_BUF_MIA\", \"2024_02_LV_BAL\", \"2024_02_LAC_CAR\", \"2024_02_NO_DAL\", \"2024_02_TB_DET\", \n",
    "    \"2024_02_IND_GB\", \"2024_02_CLE_JAX\", \"2024_02_SF_MIN\", \"2024_02_SEA_NE\", \"2024_02_NYJ_TEN\", \n",
    "    \"2024_02_NYG_WAS\", \"2024_02_LA_ARI\", \"2024_02_PIT_DEN\", \"2024_02_CIN_KC\", \"2024_02_CHI_HOU\", \n",
    "    \"2024_02_ATL_PHI\"\n",
    "]\n",
    "\n",
    "# Filter only WRs from week 1 of the 2024 season (assuming 'position' column exists)\n",
    "week_1_2024_wrs = df[(df['game_id'].str.contains(\"2024_01\")) & (df['position'] == 'WR')]\n",
    "\n",
    "# Drop duplicates by 'player' to ensure unique players\n",
    "# week_1_2024_wrs = week_1_2024_wrs.drop_duplicates(subset=['player'])\n",
    "\n",
    "# Create empty rows for each WR for each upcoming game\n",
    "empty_rows = []\n",
    "for game_id in upcoming_game_ids:\n",
    "    for index, row in week_1_2024_wrs.iterrows():\n",
    "        empty_row = {col: None for col in df.columns}  # Initialize an empty row\n",
    "        empty_row['player'] = row['player']  # Keep player name\n",
    "        empty_row['team'] = row['team']  # Keep team info\n",
    "        empty_row['position'] = row['position']  # position\n",
    "        empty_row['game_id'] = game_id  # Assign the new game_id\n",
    "        empty_rows.append(empty_row)\n",
    "\n",
    "# Convert the list of empty rows to a DataFrame\n",
    "empty_df = pd.DataFrame(empty_rows)\n",
    "\n",
    "# Drop duplicates by 'player' to ensure unique players\n",
    "empty_df = empty_df.drop_duplicates(subset=['player'])\n",
    "\n",
    "# Save the resulting dataframe to master.csv\n",
    "empty_df.to_csv('data/all_passing_rushing_receiving_test_set.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the new DataFrame (optional)\n",
    "print(empty_df.head())\n",
    "# !open data/all_passing_rushing_receiving_test_set.csv\n",
    "\n",
    "# Load the original \"all_games\" and the \"test set\" dataframes\n",
    "all_games_path = 'data/all_passing_rushing_receiving.csv'\n",
    "test_set_path = 'data/all_passing_rushing_receiving_test_set.csv'\n",
    "\n",
    "all_games_df = pd.read_csv(all_games_path)\n",
    "test_set_df = pd.read_csv(test_set_path)\n",
    "\n",
    "# Append the test set rows to the original dataset\n",
    "combined_df = pd.concat([all_games_df, test_set_df], ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_combined_path = 'data/all_passing_rushing_receiving.csv'\n",
    "combined_df.to_csv(output_combined_path, index=False)\n",
    "\n",
    "# Provide the link to download the combined dataset\n",
    "output_combined_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37917740-9c61-454a-8724-86e507303531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WR data saved to: data/wide_receivers_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract WR rows\n",
    "\n",
    "file_path = 'data/all_passing_rushing_receiving.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows where the position is 'WR' (Wide Receiver)\n",
    "wr_df = df[df['position'] == 'WR']\n",
    "\n",
    "# Drop duplicate rows based on 'player' and 'game_id'\n",
    "wr_df = wr_df.drop_duplicates(subset=['player', 'game_id'])\n",
    "\n",
    "# Updating the code to drop the specified columns\n",
    "columns_to_drop = [\n",
    "    'pass_cmp', 'pass_att', 'pass_yds', 'pass_td', 'pass_int', \n",
    "    'pass_sacked', 'pass_sacked_yds', 'pass_long', 'pass_rating', \n",
    "    'rush_att', 'rush_yds', 'rush_td', 'rush_long', 'fumbles', 'fumbles_lost'\n",
    "]\n",
    "wr_df = wr_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the filtered WR rows to a new CSV file\n",
    "wr_file_path = 'data/wide_receivers_data.csv'  # Replace with desired output file path\n",
    "wr_df.to_csv(wr_file_path, index=False)\n",
    "\n",
    "print(f'WR data saved to: {wr_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ddd092a-6076-489b-9d5f-9997ed5db223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upcoming games saved to 'upcoming_wr_stuff.csv' and removed from the original file.\n",
      "Empty DataFrame\n",
      "Columns: [player, team, targets, rec, rec_yds, rec_td, rec_long, game_id, opponent_team, home, position]\n",
      "Index: []\n",
      "                player team  targets   rec  rec_yds  rec_td  rec_long  \\\n",
      "0        Antonio Brown  PIT     11.0   9.0    133.0     1.0      37.0   \n",
      "1  Darrius Heyward-Bey  PIT      7.0   4.0     58.0     0.0      43.0   \n",
      "2       Markus Wheaton  PIT      7.0   3.0     55.0     0.0      26.0   \n",
      "3         Tyler Murphy  PIT      1.0   1.0     16.0     0.0      16.0   \n",
      "4       Julian Edelman   NE     12.0  11.0     97.0     0.0      14.0   \n",
      "\n",
      "          game_id opponent_team home position  \n",
      "0  2015_01_PIT_NE            NE    n       WR  \n",
      "1  2015_01_PIT_NE            NE    n       WR  \n",
      "2  2015_01_PIT_NE            NE    n       WR  \n",
      "3  2015_01_PIT_NE            NE    n       WR  \n",
      "4  2015_01_PIT_NE           PIT    y       WR  \n"
     ]
    }
   ],
   "source": [
    "# Extract upcoming weeks games\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/wide_receivers_data.csv')\n",
    "\n",
    "# Filter the rows where the game_id contains '2024_02'\n",
    "upcoming_games = df[df['game_id'].str.contains('2024_02', na=False)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "upcoming_games.to_csv('data/upcoming_wide_receivers_data.csv', index=False)\n",
    "\n",
    "# Drop those rows from the original DataFrame\n",
    "df_cleaned = df[~df['game_id'].str.contains('2024_02', na=False)]\n",
    "\n",
    "# Overwrite the original file with the cleaned data\n",
    "df_cleaned.to_csv('data/wide_receivers_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d1bc8-7917-474b-a12d-5d418952a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill all empty cells with 0's in upcoming games instead ^\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('data/wide_receivers_data.csv')\n",
    "\n",
    "# # Filter the rows where the game_id contains '2024_02'\n",
    "# upcoming_games = df[df['game_id'].str.contains('2024_02', na=False)]\n",
    "\n",
    "# # Fill every empty cell in the upcoming_games DataFrame with zero\n",
    "# upcoming_games = upcoming_games.fillna(0)\n",
    "\n",
    "# # Save the filtered and filled data to a new CSV file\n",
    "# upcoming_games.to_csv('data/upcoming_wide_receivers_data.csv', index=False)\n",
    "\n",
    "# # Drop those rows from the original DataFrame\n",
    "# df_cleaned = df[~df['game_id'].str.contains('2024_02', na=False)]\n",
    "\n",
    "# # Overwrite the original file with the cleaned data\n",
    "# df_cleaned.to_csv('data/wide_receivers_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c73a496a-cbd4-481f-be6c-2fe1b4f0653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open data/wide_receivers_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0f587-fc5c-4ec0-aea0-c41578d5c1f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314f0d2c-07f5-41cb-8e73-ef3bc885b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 391.9363458507265\n",
      "Coefficients: [ 0.70055401 10.70434384 11.65725871  0.30550413]\n",
      "Intercept: -0.11873471173085193\n"
     ]
    }
   ],
   "source": [
    "# Basic model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/wide_receivers_data.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert 'home' column to binary (1 if home, 0 if away)\n",
    "df['home'] = df['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "\n",
    "# Select features (X) and target (y)\n",
    "X = df[['targets', 'rec', 'rec_td', 'home']]\n",
    "y = df['rec_yds']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Print the model's coefficients\n",
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f87afb36-1ad5-4a3d-a706-2bec16f3c18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1118.9022067330293\n",
      "Coefficients: [3.33524318 1.2541757  2.54985373 1.34875499]\n",
      "Intercept: 17.826822059752217\n"
     ]
    }
   ],
   "source": [
    "# Shifting and prediciting future outcomes\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/wide_receivers_data.csv')\n",
    "\n",
    "# Convert 'home' column to binary (1 if home, 0 if away)\n",
    "df['home'] = df['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "\n",
    "# Sort by player and game_id (assuming game_id is sortable in order)\n",
    "df = df.sort_values(['player', 'game_id'])\n",
    "\n",
    "# Create lagged features by shifting the stats forward by one week\n",
    "df['prev_targets'] = df.groupby('player')['targets'].shift(1)\n",
    "df['prev_rec'] = df.groupby('player')['rec'].shift(1)\n",
    "df['prev_rec_yds'] = df.groupby('player')['rec_yds'].shift(1)\n",
    "df['prev_rec_td'] = df.groupby('player')['rec_td'].shift(1)\n",
    "\n",
    "# Drop rows with missing values (e.g., players in Week 1 will have NaN for previous weeks)\n",
    "df = df.dropna()\n",
    "\n",
    "# Select features (X) and target (y)\n",
    "X = df[['prev_targets', 'prev_rec', 'prev_rec_td', 'home']]\n",
    "y = df['rec_yds']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Print the model's coefficients\n",
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e7603c5-8d38-4caf-9175-39489fb1d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest receiving yards predictions:\n",
      "                player team          game_id  predicted_rec_yds\n",
      "59         Tyreek Hill  MIA  2024_02_BUF_MIA          72.599147\n",
      "75   Wan'Dale Robinson  NYG  2024_02_BUF_MIA          69.938841\n",
      "89    Courtland Sutton  DEN  2024_02_BUF_MIA          68.677724\n",
      "123     Garrett Wilson  NYJ  2024_02_BUF_MIA          66.180306\n",
      "36        Keenan Allen  CHI  2024_02_BUF_MIA          64.919189\n",
      "11          A.J. Brown  PHI  2024_02_BUF_MIA          63.820961\n",
      "122       Allen Lazard  NYJ  2024_02_BUF_MIA          62.722732\n",
      "0          Zay Flowers  BAL  2024_02_BUF_MIA          62.421772\n",
      "97         CeeDee Lamb  DAL  2024_02_BUF_MIA          61.791213\n",
      "119   Jameson Williams  DET  2024_02_BUF_MIA          60.062426\n",
      "4          Rashee Rice   KC  2024_02_BUF_MIA          59.293795\n",
      "110       Chris Godwin   TB  2024_02_BUF_MIA          58.195567\n",
      "124       Deebo Samuel   SF  2024_02_BUF_MIA          58.032678\n",
      "103       Amari Cooper  CLE  2024_02_BUF_MIA          56.141003\n",
      "12       DeVonta Smith  PHI  2024_02_BUF_MIA          55.535261\n",
      "102        Jerry Jeudy  CLE  2024_02_BUF_MIA          55.042775\n",
      "49        Nico Collins  HOU  2024_02_BUF_MIA          54.904702\n",
      "22         Greg Dortch  ARI  2024_02_BUF_MIA          54.904702\n",
      "34          D.J. Moore  CHI  2024_02_BUF_MIA          54.274144\n",
      "87       Josh Reynolds  DEN  2024_02_BUF_MIA          54.274144\n"
     ]
    }
   ],
   "source": [
    "# Predicting week 2 upcoming receiving yards\n",
    "# WORKING\n",
    "\n",
    "df_historical = pd.read_csv('data/wide_receivers_data.csv')\n",
    "df_upcoming = pd.read_csv('data/upcoming_wide_receivers_data.csv')\n",
    "\n",
    "# Convert 'home' column to binary (1 if home, 0 if away) in both datasets\n",
    "df_historical['home'] = df_historical['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "df_upcoming['home'] = df_upcoming['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "\n",
    "# Extract season and week from game_id\n",
    "df_historical['season'] = df_historical['game_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Filter for the 2023 and 2024 seasons only\n",
    "df_recent = df_historical[df_historical['season'].isin([2023, 2024])]\n",
    "\n",
    "# Set a threshold to filter out WRs who haven't had more than 10 combined targets across 2023 and 2024\n",
    "threshold = 3\n",
    "wr_totals_recent = df_recent.groupby('player')['targets'].sum()  # Sum of targets per player for 2023 and 2024\n",
    "eligible_wrs = wr_totals_recent[wr_totals_recent >= threshold].index  # Players with targets >= threshold\n",
    "\n",
    "# Filter the historical dataset to only include eligible WRs\n",
    "df_historical = df_historical[df_historical['player'].isin(eligible_wrs)]\n",
    "\n",
    "# Sort the historical data by player and game_id\n",
    "df_historical = df_historical.sort_values(['player', 'game_id'])\n",
    "\n",
    "# Create lagged features from historical data by shifting the stats forward by one game\n",
    "df_historical['prev_targets'] = df_historical.groupby('player')['targets'].shift(1)\n",
    "df_historical['prev_rec'] = df_historical.groupby('player')['rec'].shift(1)\n",
    "df_historical['prev_rec_yds'] = df_historical.groupby('player')['rec_yds'].shift(1)\n",
    "df_historical['prev_rec_td'] = df_historical.groupby('player')['rec_td'].shift(1)\n",
    "\n",
    "# Drop rows with missing lagged data (first game for each player will have NaNs in lagged features)\n",
    "df_historical = df_historical.dropna()\n",
    "\n",
    "# Get the Week 1 games from the historical data (assuming 'game_id' contains '2024_01' for Week 1)\n",
    "week_1_2024 = df_historical[df_historical['game_id'].str.contains('2024_01')]\n",
    "\n",
    "# Merge Week 1 data into the upcoming Week 2 games to serve as \"previous game\" data\n",
    "df_upcoming = df_upcoming.merge(week_1_2024[['player', 'targets', 'rec', 'rec_td', 'rec_yds']],\n",
    "                                on='player', \n",
    "                                how='left', \n",
    "                                suffixes=('', '_prev'))\n",
    "\n",
    "# Rename the columns to match the feature names\n",
    "df_upcoming.rename(columns={'targets_prev': 'prev_targets', 'rec_prev': 'prev_rec', \n",
    "                            'rec_td_prev': 'prev_rec_td', 'rec_yds_prev': 'prev_rec_yds'}, inplace=True)\n",
    "\n",
    "# Fill missing values in the upcoming games (for players without Week 1 data)\n",
    "df_upcoming['prev_targets'] = df_upcoming['prev_targets'].fillna(0)\n",
    "df_upcoming['prev_rec'] = df_upcoming['prev_rec'].fillna(0)\n",
    "df_upcoming['prev_rec_td'] = df_upcoming['prev_rec_td'].fillna(0)\n",
    "df_upcoming['home'] = df_upcoming['home'].fillna(0)\n",
    "\n",
    "# Select features from the upcoming games (X_test)\n",
    "X_test = df_upcoming[['prev_targets', 'prev_rec', 'prev_rec_td', 'home']]\n",
    "\n",
    "# Train the Linear Regression model (if you haven't already trained it)\n",
    "X_train = df_historical[['prev_targets', 'prev_rec', 'prev_rec_td', 'home']]\n",
    "y_train = df_historical['rec_yds']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict receiving yards for the upcoming games\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Add the predictions to the upcoming games DataFrame\n",
    "df_upcoming['predicted_rec_yds'] = y_pred\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "df_upcoming.to_csv('data/upcoming_wr_predictions.csv', index=False)\n",
    "\n",
    "# Optionally, print the predictions\n",
    "# print(df_upcoming[['player', 'team', 'game_id', 'predicted_rec_yds']])\n",
    "\n",
    "# Sort the DataFrame by predicted receiving yards in descending order\n",
    "print(\"Highest receiving yards predictions:\")\n",
    "top_10_predictions = df_upcoming.sort_values(by='predicted_rec_yds', ascending=False).head(20)\n",
    "\n",
    "# Print the top 10 players with their predicted receiving yards\n",
    "print(top_10_predictions[['player', 'team', 'game_id', 'predicted_rec_yds']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "245faf64-1e7c-4b02-8d46-9e4103fa9b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest receptions predictions:\n",
      "                player team          game_id  predicted_rec\n",
      "59         Tyreek Hill  MIA  2024_02_BUF_MIA       5.517419\n",
      "75   Wan'Dale Robinson  NYG  2024_02_BUF_MIA       5.328013\n",
      "123     Garrett Wilson  NYJ  2024_02_BUF_MIA       5.102099\n",
      "89    Courtland Sutton  DEN  2024_02_BUF_MIA       5.023092\n",
      "0          Zay Flowers  BAL  2024_02_BUF_MIA       4.876184\n",
      "4          Rashee Rice   KC  2024_02_BUF_MIA       4.802731\n",
      "36        Keenan Allen  CHI  2024_02_BUF_MIA       4.797177\n",
      "110       Chris Godwin   TB  2024_02_BUF_MIA       4.766222\n",
      "11          A.J. Brown  PHI  2024_02_BUF_MIA       4.760669\n",
      "122       Allen Lazard  NYJ  2024_02_BUF_MIA       4.724160\n",
      "97         CeeDee Lamb  DAL  2024_02_BUF_MIA       4.723724\n",
      "12       DeVonta Smith  PHI  2024_02_BUF_MIA       4.576816\n",
      "119   Jameson Williams  DET  2024_02_BUF_MIA       4.534754\n",
      "124       Deebo Samuel   SF  2024_02_BUF_MIA       4.497809\n",
      "49        Nico Collins  HOU  2024_02_BUF_MIA       4.424355\n",
      "22         Greg Dortch  ARI  2024_02_BUF_MIA       4.424355\n",
      "87       Josh Reynolds  DEN  2024_02_BUF_MIA       4.271895\n",
      "34          D.J. Moore  CHI  2024_02_BUF_MIA       4.271895\n",
      "18      George Pickens  PIT  2024_02_BUF_MIA       4.198441\n",
      "93       Tyler Lockett  SEA  2024_02_BUF_MIA       4.198441\n"
     ]
    }
   ],
   "source": [
    "# Predicting week 2 upcoming receptions\n",
    "# WORKING\n",
    "\n",
    "df_historical = pd.read_csv('data/wide_receivers_data.csv')\n",
    "df_upcoming = pd.read_csv('data/upcoming_wide_receivers_data.csv')\n",
    "\n",
    "# Convert 'home' column to binary (1 if home, 0 if away)\n",
    "df_historical['home'] = df_historical['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "df_upcoming['home'] = df_upcoming['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "\n",
    "# Extract season and week from game_id\n",
    "df_historical['season'] = df_historical['game_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Filter for the 2023 and 2024 seasons only\n",
    "df_recent = df_historical[df_historical['season'].isin([2023, 2024])]\n",
    "\n",
    "# Set a threshold to filter out WRs who haven't had more than 10 combined targets across 2023 and 2024\n",
    "threshold = 3\n",
    "wr_totals_recent = df_recent.groupby('player')['targets'].sum()  # Sum of targets per player for 2023 and 2024\n",
    "eligible_wrs = wr_totals_recent[wr_totals_recent >= threshold].index  # Players with targets >= threshold\n",
    "\n",
    "# Filter the historical dataset to only include eligible WRs\n",
    "df_historical = df_historical[df_historical['player'].isin(eligible_wrs)]\n",
    "\n",
    "# Sort the historical data by player and game_id\n",
    "df_historical = df_historical.sort_values(['player', 'game_id'])\n",
    "\n",
    "# Create lagged features from historical data by shifting the stats forward by one game\n",
    "df_historical['prev_targets'] = df_historical.groupby('player')['targets'].shift(1)\n",
    "df_historical['prev_rec'] = df_historical.groupby('player')['rec'].shift(1)\n",
    "df_historical['prev_rec_yds'] = df_historical.groupby('player')['rec_yds'].shift(1)\n",
    "df_historical['prev_rec_td'] = df_historical.groupby('player')['rec_td'].shift(1)\n",
    "\n",
    "# Drop rows with missing lagged data (first game for each player will have NaNs in lagged features)\n",
    "df_historical = df_historical.dropna()\n",
    "\n",
    "# Get the Week 1 games from the historical data (assuming 'game_id' contains '2024_01' for Week 1)\n",
    "week_1_2024 = df_historical[df_historical['game_id'].str.contains('2024_01')]\n",
    "\n",
    "# Merge Week 1 data into the upcoming Week 2 games to serve as \"previous game\" data\n",
    "df_upcoming = df_upcoming.merge(week_1_2024[['player', 'targets', 'rec', 'rec_td', 'rec_yds']],\n",
    "                                on='player', \n",
    "                                how='left', \n",
    "                                suffixes=('', '_prev'))\n",
    "\n",
    "# Rename the columns to match the feature names\n",
    "df_upcoming.rename(columns={'targets_prev': 'prev_targets', 'rec_prev': 'prev_rec', \n",
    "                            'rec_td_prev': 'prev_rec_td', 'rec_yds_prev': 'prev_rec_yds'}, inplace=True)\n",
    "\n",
    "# Fill missing values in the upcoming games (for players without Week 1 data)\n",
    "df_upcoming['prev_targets'] = df_upcoming['prev_targets'].fillna(0)\n",
    "df_upcoming['prev_rec'] = df_upcoming['prev_rec'].fillna(0)\n",
    "df_upcoming['prev_rec_td'] = df_upcoming['prev_rec_td'].fillna(0)\n",
    "df_upcoming['home'] = df_upcoming['home'].fillna(0)\n",
    "\n",
    "# Select features from the upcoming games (X_test)\n",
    "X_test = df_upcoming[['prev_targets', 'prev_rec', 'prev_rec_td', 'home']]\n",
    "\n",
    "# Train the Linear Regression model (for predicting receptions)\n",
    "X_train = df_historical[['prev_targets', 'prev_rec', 'prev_rec_td', 'home']]\n",
    "y_train = df_historical['rec']  # Predict receptions instead of receiving yards\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict receptions for the upcoming games\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Add the predictions to the upcoming games DataFrame\n",
    "df_upcoming['predicted_rec'] = y_pred\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "df_upcoming.to_csv('data/upcoming_wr_predictions_receptions.csv', index=False)\n",
    "\n",
    "# Optionally, print the predictions\n",
    "# print(df_upcoming[['player', 'team', 'game_id', 'predicted_rec']])\n",
    "\n",
    "# Sort the DataFrame by predicted receptions in descending order\n",
    "print(\"Highest receptions predictions:\")\n",
    "top_10_predictions = df_upcoming.sort_values(by='predicted_rec', ascending=False).head(20)\n",
    "\n",
    "# Print the top 10 players with their predicted receptions\n",
    "print(top_10_predictions[['player', 'team', 'game_id', 'predicted_rec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc81c0-4ed4-457f-b4bb-bb02996a8aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84fbbed-75fc-4b4f-97f9-b89adc41c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160d482-2c8b-4d84-a589-f5be6a2db312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3056ab3-39a4-4496-a8c4-1ae9351a9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Added rolling averages ^\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('data/wide_receivers_data.csv')\n",
    "\n",
    "# # Convert 'home' column to binary (1 if home, 0 if away)\n",
    "# df['home'] = df['home'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "\n",
    "# # Sort by player and game_id (assuming game_id is sortable in order)\n",
    "# df = df.sort_values(['player', 'game_id'])\n",
    "\n",
    "# # Create lagged features by shifting the stats forward by one week\n",
    "# df['prev_targets'] = df.groupby('player')['targets'].shift(1)\n",
    "# df['prev_rec'] = df.groupby('player')['rec'].shift(1)\n",
    "# df['prev_rec_yds'] = df.groupby('player')['rec_yds'].shift(1)\n",
    "# df['prev_rec_td'] = df.groupby('player')['rec_td'].shift(1)\n",
    "\n",
    "# # Rolling averages (e.g., average targets over the last 3 games)\n",
    "# df['avg_targets_last_3'] = df.groupby('player')['targets'].rolling(3).mean().shift(1).reset_index(level=0, drop=True)\n",
    "# df['avg_rec_last_3'] = df.groupby('player')['rec'].rolling(3).mean().shift(1).reset_index(level=0, drop=True)\n",
    "\n",
    "# # Drop rows with missing values (e.g., players in Week 1 will have NaN for previous weeks)\n",
    "# df = df.dropna()\n",
    "\n",
    "# # Select features (X) and target (y)\n",
    "# X = df[['prev_targets', 'prev_rec', 'prev_rec_td', 'home', 'avg_targets_last_3', 'avg_rec_last_3']]\n",
    "# y = df['rec_yds']\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a Linear Regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# # Print the model's coefficients\n",
    "# print(f'Coefficients: {model.coef_}')\n",
    "# print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed1121-6d23-4984-9ba1-7e0a466d290e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad301701-640d-4c13-b2f9-309e6cd13a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7b006-9395-471d-8d8c-c8e3a42b47eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec571f-e6c3-439b-9677-38b2257147fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc46ab-7037-4d0d-918c-a105d58a5ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df753776-1520-401a-bc57-9e400618424e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aaf14a-e629-4148-b97a-691ccf4d9d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6e9c9-5e1c-4cda-9c67-5bbed3447f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc92d02-e789-49e7-8b7c-fdd799a685a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed71d27-d0b0-4e4d-9967-9b5366a3baca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1dac237-815b-434e-88ab-16fc7d644988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to week2_predictions_based_on_week1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hd/r4k9j4m15vd1bc_tnk5pn5_c0000gn/T/ipykernel_26765/57313198.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('player').apply(agg_weekly_data)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('data/master.csv')\n",
    "\n",
    "# Step 2: Filter for players who have receiving data\n",
    "df = df[df['rec'] > 0]\n",
    "\n",
    "# Step 3: Extract season and week from game_id\n",
    "df['season'] = df['game_id'].apply(lambda x: int(x.split('_')[0]))  # Extract season from game_id\n",
    "df['week'] = df['game_id'].apply(lambda x: int(x.split('_')[1].lstrip('0')))  # Extract week from game_id\n",
    "\n",
    "# Step 4: Sort by player and week to ensure proper ordering\n",
    "df = df.sort_values(by=['player', 'season', 'week'])\n",
    "\n",
    "# Step 5: Aggregating data up to the week before the current game\n",
    "def agg_weekly_data(player_df):\n",
    "    \"\"\"\n",
    "    This function aggregates player statistics up to the current week.\n",
    "    For example, for week 6, the data will be based on weeks 1 to 5.\n",
    "    \"\"\"\n",
    "    player_df['avg_targets'] = player_df['targets'].shift(1).expanding().mean()\n",
    "    player_df['avg_rec_yds'] = player_df['rec_yds'].shift(1).expanding().mean()\n",
    "    player_df['avg_aDOT'] = player_df['rec_yds'].shift(1).expanding().mean()\n",
    "    return player_df\n",
    "\n",
    "# Apply the aggregation for each player\n",
    "df = df.groupby('player').apply(agg_weekly_data)\n",
    "\n",
    "# Step 6: Fill NaN values that may appear due to the shifting process\n",
    "df['avg_targets'] = df['avg_targets'].fillna(0)\n",
    "df['avg_rec_yds'] = df['avg_rec_yds'].fillna(0)\n",
    "df['avg_aDOT'] = df['avg_aDOT'].fillna(0)\n",
    "\n",
    "# Step 7: We will use Week 1's data as features to predict Week 2\n",
    "# Training set: Use past seasons and Week 1 of 2024\n",
    "train_df = df[(df['season'].between(2020, 2023)) | ((df['season'] == 2024) & (df['week'] == 1))]\n",
    "\n",
    "# Step 8: Predicting for Week 2 based on Week 1 data (shift Week 1 data forward)\n",
    "test_df = train_df[train_df['week'] == 1].copy()  # Copy Week 1 data\n",
    "test_df['week'] = 2  # Set the week to 2 to simulate Week 2\n",
    "\n",
    "# Step 9: Prepare the data for modeling\n",
    "y_train = train_df['rec_yds']\n",
    "X_train = train_df[['avg_targets', 'avg_rec_yds', 'avg_aDOT']]  # Use aggregated averages as features for training\n",
    "\n",
    "# Use Week 1 data for Week 2 predictions\n",
    "X_test = test_df[['avg_targets', 'avg_rec_yds', 'avg_aDOT']]\n",
    "\n",
    "# Step 10: Build and Train the Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 11: Predict receiving yards for Week 2 based on Week 1 data\n",
    "test_df['Linear Prediction'] = linear_model.predict(X_test)\n",
    "\n",
    "# Step 12: Save the predictions to a CSV file for future analysis\n",
    "output_file = 'week2_predictions_based_on_week1.csv'\n",
    "test_df[['player', 'game_id', 'Linear Prediction']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3b2e64-ead2-4431-9b2c-a0f2ba7599e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open week2_predictions_based_on_week1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6e36f-0b77-4de3-a1bf-29571673abae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9af96f9-585d-4b87-9700-ec9a70759e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hd/r4k9j4m15vd1bc_tnk5pn5_c0000gn/T/ipykernel_26765/1775109604.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df_train.groupby('player').apply(agg_weekly_data)\n",
      "/var/folders/hd/r4k9j4m15vd1bc_tnk5pn5_c0000gn/T/ipykernel_26765/1775109604.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_test = df_test.groupby('player').apply(agg_weekly_data)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'avg_targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avg_targets'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(agg_weekly_data)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Fill NaN values in the test set (Week 2)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_targets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_targets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_rec_yds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_rec_yds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_aDOT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_aDOT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avg_targets'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Load the datasets (adjust the paths if needed)\n",
    "df_train = pd.read_csv('data/all_passing_rushing_receiving.csv')\n",
    "df_test = pd.read_csv('data/all_passing_rushing_receiving_test_set.csv')\n",
    "\n",
    "# Step 2: Filter for players who have receiving data in both train and test sets\n",
    "df_train = df_train[df_train['rec'] > 0]\n",
    "df_test = df_test[df_test['rec'] > 0]\n",
    "\n",
    "# Step 3: Extract season and week from game_id\n",
    "df_train['season'] = df_train['game_id'].apply(lambda x: int(x.split('_')[0]))  # Extract season from game_id\n",
    "df_train['week'] = df_train['game_id'].apply(lambda x: int(x.split('_')[1].lstrip('0')))  # Extract week from game_id\n",
    "\n",
    "df_test['season'] = df_test['game_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "df_test['week'] = df_test['game_id'].apply(lambda x: int(x.split('_')[1].lstrip('0')))\n",
    "\n",
    "# Step 4: Sort by player and week to ensure proper ordering in the training data\n",
    "df_train = df_train.sort_values(by=['player', 'season', 'week'])\n",
    "\n",
    "# Step 5: Aggregating data up to the week before the current game for the training set\n",
    "def agg_weekly_data(player_df):\n",
    "    \"\"\"\n",
    "    This function aggregates player statistics up to the current week.\n",
    "    For example, for week 6, the data will be based on weeks 1 to 5.\n",
    "    \"\"\"\n",
    "    player_df['avg_targets'] = player_df['targets'].shift(1).expanding().mean()\n",
    "    player_df['avg_rec_yds'] = player_df['rec_yds'].shift(1).expanding().mean()\n",
    "    player_df['avg_aDOT'] = player_df['rec_yds'].shift(1).expanding().mean()\n",
    "    return player_df\n",
    "\n",
    "# Apply the aggregation for each player in the training set\n",
    "df_train = df_train.groupby('player').apply(agg_weekly_data)\n",
    "\n",
    "# Step 6: Fill NaN values in the training set\n",
    "df_train['avg_targets'] = df_train['avg_targets'].fillna(0)\n",
    "df_train['avg_rec_yds'] = df_train['avg_rec_yds'].fillna(0)\n",
    "df_train['avg_aDOT'] = df_train['avg_aDOT'].fillna(0)\n",
    "\n",
    "# Step 7: In the test set, calculate the aggregated averages in a similar way\n",
    "df_test = df_test.groupby('player').apply(agg_weekly_data)\n",
    "\n",
    "# Fill NaN values in the test set (Week 2)\n",
    "df_test['avg_targets'] = df_test['avg_targets'].fillna(0)\n",
    "df_test['avg_rec_yds'] = df_test['avg_rec_yds'].fillna(0)\n",
    "df_test['avg_aDOT'] = df_test['avg_aDOT'].fillna(0)\n",
    "\n",
    "# Step 8: Prepare the data for modeling\n",
    "y_train = df_train['rec_yds']\n",
    "X_train = df_train[['avg_targets', 'avg_rec_yds', 'avg_aDOT']]  # Use aggregated averages as features for training\n",
    "\n",
    "# Use aggregated averages in the test set for predictions\n",
    "X_test = df_test[['avg_targets', 'avg_rec_yds', 'avg_aDOT']]\n",
    "\n",
    "# Step 9: Build and Train the Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Predict receiving yards for Week 2 games in the test set\n",
    "df_test['Linear Prediction'] = linear_model.predict(X_test)\n",
    "\n",
    "# Step 11: Save the predictions to a CSV file for future analysis\n",
    "output_file = 'week2_predictions_final_fixed.csv'\n",
    "df_test[['player', 'game_id', 'Linear Prediction']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9b98b-9227-48c0-8039-d7b22bb9f3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
