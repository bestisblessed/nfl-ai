{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55da3e67-e39b-4c54-a5ce-443566785444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda37d5-5116-4bc3-9221-8729c5b7a5c4",
   "metadata": {},
   "source": [
    "# Probability QB Will Throw a Touchdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c88d586-0afe-4cdc-9596-c63920362cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['opponent_defense_strength']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/wx/m1tmq8gx4_v321trybkxcg9m0000gn/T/ipykernel_11712/3838148897.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Target variable: whether the QB threw an interception\u001b[39;00m\n\u001b[32m     26\u001b[39m player_stats_with_defense_cleaned[\u001b[33m'threw_interception'\u001b[39m] = player_stats_with_defense_cleaned[\u001b[33m'interceptions'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Drop rows with missing values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m player_stats_with_defense_cleaned = player_stats_with_defense_cleaned.dropna(subset=features + [\u001b[33m'threw_interception'\u001b[39m])\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[32m     32\u001b[39m X = player_stats_with_defense_cleaned[features]\n",
      "\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['opponent_defense_strength']"
     ]
    }
   ],
   "source": [
    "# Train & evaluate logistic regression model\n",
    "\n",
    "player_stats_with_defense = pd.read_csv('data/PlayerStats.csv', low_memory=False)\n",
    "\n",
    "# Step 1: Remove rows where all relevant stats are zeros\n",
    "stats_columns = ['attempts', 'completions', 'passing_yards', 'passing_tds', 'sacks']\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense[\n",
    "    ~((player_stats_with_defense[stats_columns] == 0).all(axis=1))\n",
    "]\n",
    "\n",
    "# Step 2: Filter data to only include seasons 2020, 2021, 2022, 2023\n",
    "seasons_to_keep = [2020, 2021, 2022, 2023]\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned[\n",
    "    player_stats_with_defense_cleaned['season'].isin(seasons_to_keep)\n",
    "]\n",
    "\n",
    "# Step 3: Filter to only keep rows where position is QB\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned[\n",
    "    player_stats_with_defense_cleaned['position'] == 'QB'\n",
    "]\n",
    "\n",
    "# Basic feature selection\n",
    "features = ['attempts', 'completions', 'passing_yards', 'passing_tds', 'sacks', 'opponent_defense_strength']\n",
    "\n",
    "# Target variable: whether the QB threw an interception\n",
    "player_stats_with_defense_cleaned['threw_interception'] = player_stats_with_defense_cleaned['interceptions'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Drop rows with missing values\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned.dropna(subset=features + ['threw_interception'])\n",
    "\n",
    "# Split the data\n",
    "X = player_stats_with_defense_cleaned[features]\n",
    "y = player_stats_with_defense_cleaned['threw_interception']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56c9515-21e6-4976-8f95-b6efe056cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "Accuracy: 0.6130\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.66       277\n",
      "           1       0.60      0.52      0.56       245\n",
      "\n",
      "    accuracy                           0.61       522\n",
      "   macro avg       0.61      0.61      0.61       522\n",
      "weighted avg       0.61      0.61      0.61       522\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[192  85]\n",
      " [117 128]]\n",
      "\n",
      "XGBoost Model\n",
      "Accuracy: 0.5747\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62       277\n",
      "           1       0.55      0.50      0.52       245\n",
      "\n",
      "    accuracy                           0.57       522\n",
      "   macro avg       0.57      0.57      0.57       522\n",
      "weighted avg       0.57      0.57      0.57       522\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[178  99]\n",
      " [123 122]]\n"
     ]
    }
   ],
   "source": [
    "# Compare Random Forest and XGBoost\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Model\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report_rf)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_rf)\n",
    "\n",
    "# Evaluation for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"\\nXGBoost Model\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report_xgb)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f148ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7548\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.76       255\n",
      "           1       0.79      0.70      0.74       263\n",
      "\n",
      "    accuracy                           0.75       518\n",
      "   macro avg       0.76      0.76      0.75       518\n",
      "weighted avg       0.76      0.75      0.75       518\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[206  49]\n",
      " [ 78 185]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/td/.pyenv/versions/3.12.0/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED VERSION - Train & evaluate logistic regression model\n",
    "\n",
    "player_stats_with_defense = pd.read_csv('data/PlayerStats.csv', low_memory=False)\n",
    "\n",
    "# Step 1: Remove rows where all relevant stats are zeros\n",
    "stats_columns = ['attempts', 'completions', 'passing_yards', 'passing_tds', 'sacks']\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense[\n",
    "    ~((player_stats_with_defense[stats_columns] == 0).all(axis=1))\n",
    "]\n",
    "\n",
    "# Step 2: Filter data to only include seasons 2020, 2021, 2022, 2023\n",
    "seasons_to_keep = [2020, 2021, 2022, 2023]\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned[\n",
    "    player_stats_with_defense_cleaned['season'].isin(seasons_to_keep)\n",
    "]\n",
    "\n",
    "# Step 3: Filter to only keep rows where position is QB\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned[\n",
    "    player_stats_with_defense_cleaned['position'] == 'QB'\n",
    "]\n",
    "\n",
    "# FIXED: Updated feature selection - using only available columns\n",
    "features = ['attempts', 'completions', 'passing_yards', 'passing_tds', 'sacks', 'passing_epa', 'passing_air_yards']\n",
    "\n",
    "# Target variable: whether the QB threw an interception\n",
    "player_stats_with_defense_cleaned['threw_interception'] = player_stats_with_defense_cleaned['interceptions'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Drop rows with missing values\n",
    "player_stats_with_defense_cleaned = player_stats_with_defense_cleaned.dropna(subset=features + ['threw_interception'])\n",
    "\n",
    "# Split the data\n",
    "X = player_stats_with_defense_cleaned[features]\n",
    "y = player_stats_with_defense_cleaned['threw_interception']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fc09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interception Probabilities (No Interception, Interception):\n",
      "[[0.52892704 0.47107296]\n",
      " [0.05948888 0.94051112]\n",
      " [0.37968775 0.62031225]\n",
      " [0.68113264 0.31886736]\n",
      " [0.14430437 0.85569563]\n",
      " [0.5187497  0.4812503 ]\n",
      " [0.76340461 0.23659539]\n",
      " [0.88442821 0.11557179]\n",
      " [0.76296334 0.23703666]\n",
      " [0.00740392 0.99259608]]\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED PREDICTION CODE\n",
    "# Here's the full code that includes both the shifting of data and the use of historical averages \n",
    "# to estimate values for upcoming games:\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Suppress sklearn RuntimeWarnings about overflow and divide by zero in matmul\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"sklearn\")\n",
    "\n",
    "# Compute average stats for each player\n",
    "average_stats = player_stats_with_defense_cleaned.groupby('player_display_name').agg({\n",
    "    'attempts': 'mean',\n",
    "    'completions': 'mean',\n",
    "    'passing_yards': 'mean',\n",
    "    'passing_tds': 'mean',\n",
    "    'sacks': 'mean',\n",
    "    'passing_epa': 'mean',\n",
    "    'passing_air_yards': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 2: Shift data by one game to predict the next game based on the previous one\n",
    "shifted_stats = player_stats_with_defense_cleaned.groupby('player_display_name')[features].shift(1)\n",
    "\n",
    "# Combine shifted stats with historical averages\n",
    "# If shifted stats are available, they take precedence; otherwise, use historical averages\n",
    "predictions_data = shifted_stats.combine_first(average_stats.set_index('player_display_name')).reset_index()\n",
    "\n",
    "# FIXED: Fill NaNs in numeric columns only (using features instead of undefined numeric_features)\n",
    "predictions_data[features] = predictions_data[features].fillna(predictions_data[features].mean())\n",
    "\n",
    "# Ensure the predictions_data has the same structure as your training data\n",
    "predictions_data = predictions_data[features]\n",
    "\n",
    "# Step 3: Predict probabilities for upcoming games\n",
    "interception_probabilities = model.predict_proba(predictions_data)\n",
    "\n",
    "# Print the probabilities\n",
    "print(\"Interception Probabilities (No Interception, Interception):\")\n",
    "print(interception_probabilities[:10])  # Show first 10 predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e766a",
   "metadata": {},
   "source": [
    "# CORRECTED: Probability QB Will Throw an Interception\n",
    "\n",
    "This notebook predicts the probability that a quarterback will throw an interception in their next game based on their recent performance statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95301a27-ef9b-498d-8273-6479d22da1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['opponent_defense_strength'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Here’s the full code that includes both the shifting of data and the use of historical averages \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# to estimate values for upcoming games:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m average_stats = \u001b[43mplayer_stats_with_defense_cleaned\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplayer_display_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mattempts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcompletions\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpassing_yards\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpassing_tds\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msacks\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopponent_defense_strength\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Step 2: Shift data by one game to predict the next game based on the previous one\u001b[39;00m\n\u001b[32m     14\u001b[39m shifted_stats = player_stats_with_defense_cleaned.groupby(\u001b[33m'\u001b[39m\u001b[33mplayer_display_name\u001b[39m\u001b[33m'\u001b[39m)[features].shift(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:1608\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1603\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1605\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1606\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1607\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1608\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1611\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:462\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m is_groupby = \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[32m    461\u001b[39m func = cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m.func)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m is_non_unique_col = (\n\u001b[32m    465\u001b[39m     selected_obj.ndim == \u001b[32m2\u001b[39m\n\u001b[32m    466\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj.columns.nunique() < \u001b[38;5;28mlen\u001b[39m(selected_obj.columns)\n\u001b[32m    467\u001b[39m )\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:663\u001b[39m, in \u001b[36mApply.normalize_dictlike_arg\u001b[39m\u001b[34m(self, how, obj, func)\u001b[39m\n\u001b[32m    661\u001b[39m     cols = Index(\u001b[38;5;28mlist\u001b[39m(func.keys())).difference(obj.columns, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m aggregator_types = (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"Column(s) ['opponent_defense_strength'] do not exist\""
     ]
    }
   ],
   "source": [
    "# Here’s the full code that includes both the shifting of data and the use of historical averages \n",
    "# to estimate values for upcoming games:\n",
    "\n",
    "average_stats = player_stats_with_defense_cleaned.groupby('player_display_name').agg({\n",
    "    'attempts': 'mean',\n",
    "    'completions': 'mean',\n",
    "    'passing_yards': 'mean',\n",
    "    'passing_tds': 'mean',\n",
    "    'sacks': 'mean',\n",
    "    'opponent_defense_strength': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 2: Shift data by one game to predict the next game based on the previous one\n",
    "shifted_stats = player_stats_with_defense_cleaned.groupby('player_display_name')[features].shift(1)\n",
    "\n",
    "# Combine shifted stats with historical averages\n",
    "# If shifted stats are available, they take precedence; otherwise, use historical averages\n",
    "predictions_data = shifted_stats.combine_first(average_stats.set_index('player_display_name')).reset_index()\n",
    "\n",
    "# Fill NaNs in numeric columns only\n",
    "predictions_data[numeric_features] = predictions_data[numeric_features].fillna(predictions_data[numeric_features].mean())\n",
    "\n",
    "# Ensure the predictions_data has the same structure as your training data\n",
    "predictions_data = predictions_data[features]\n",
    "\n",
    "# Step 3: Predict probabilities for upcoming games\n",
    "interception_probabilities = model.predict_proba(predictions_data)\n",
    "\n",
    "# Print the probabilities\n",
    "interception_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bdcac-6cf7-4546-8b8a-415933292ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb287f14-6840-4074-b651-a5edcfa5a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c464a09-793f-4a22-abe2-900901da8ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
