{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db079b93-4649-4a3c-a678-cd27cae5c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb898d5-ba38-4674-b25f-81122aa5b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data/ directory and saved to root CSVs\n",
      "Player stats shape: (45316, 27)\n",
      "Available columns: ['player', 'player_id', 'team', 'pass_cmp', 'pass_att', 'pass_yds', 'pass_td', 'pass_int', 'pass_sacked', 'pass_sacked_yds', 'pass_long', 'pass_rating', 'rush_att', 'rush_yds', 'rush_td', 'rush_long', 'targets', 'rec', 'rec_yds', 'rec_td', 'rec_long', 'fumbles', 'fumbles_lost', 'game_id', 'opponent_team', 'home', 'position']\n"
     ]
    }
   ],
   "source": [
    "# Load data from CSV files in data/ directory\n",
    "\n",
    "teams_df = pd.read_csv('data/Teams_OCT_10_2025.csv')\n",
    "games_df = pd.read_csv('data/Games_OCT_10_2025.csv')\n",
    "player_stats_df = pd.read_csv('data/all_passing_rushing_receiving.csv')\n",
    "rosters_df = pd.read_csv('data/Rosters_OCT_10_2025.csv')\n",
    "\n",
    "# Save to root CSVs for compatibility with rest of notebook\n",
    "teams_df.to_csv('Teams.csv', index=False)\n",
    "games_df.to_csv('Games.csv', index=False)\n",
    "player_stats_df.to_csv('PlayerStats.csv', index=False)\n",
    "rosters_df.to_csv('Rosters.csv', index=False)\n",
    "\n",
    "print(\"Loaded data from data/ directory and saved to root CSVs\")\n",
    "print(f\"Player stats shape: {player_stats_df.shape}\")\n",
    "print(f\"Available columns: {list(player_stats_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef300e31-c821-429e-81e3-29d719fee3f1",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost is an implementation of Gradient Boosted decision trees. XGBoost models majorly dominate in many Kaggle Competitions.\n",
    "\n",
    "In this algorithm, decision trees are created in sequential form. Weights play an important role in XGBoost. Weights are assigned to all the independent variables which are then fed into the decision tree which predicts results. The weight of variables predicted wrong by the tree is increased and these variables are then fed to the second decision tree. These individual classifiers/predictors then ensemble to give a strong and more precise model. It can work on regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "##### https://www.geeksforgeeks.org/xgboost/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e30414-4fa7-4015-9b6d-b65315ce88b0",
   "metadata": {},
   "source": [
    "### Bayesian Inference\n",
    "When I talk about inference models, I’m usually talking about Bayesian inference. Bayesian inference allows us to use prior information to estimate our target. It’s very rare that you have literally no clue about what you’re trying to estimate. Bayesian inference allows us to create a “weakly informative” prior. I know that a player’s passing touchdowns per game will be positive. I know it will be less than something absurd, like 20 touchdowns per game. I can use this sort of information when crafting a model.\n",
    "\n",
    "Let’s say we wanted to estimate Lamar Jackson’s passing touchdown output in week 3 of the 2019 season. The statistics classes that I took growing up didn’t have a great approach to this problem. One method might be to average his production in weeks one and two and use that as a guess. Or, we could use last season’s average. It’s clear that both of these approaches are flawed. In weeks one and two, he average 3.5 passing touchdowns. As those familiar with football know, 3.5 passing touchdowns per game is completely unprecedented in a low volume passing offense. He also played a very weak Miami Dolphins team that would inflate his numbers. Last year, he averaged 0.86 touchdowns per game in the regular season. Even with a bigger sample size, that’s also unsatisfactory. He’s young, and he’s probably made some sort of improvement during the offseason. The team also committed to building around his skillset with personnel.\n",
    "\n",
    "It’s easy to say his passing touchdown output going forward would be somewhere between 0.85 and 3.5. It’s not easy to say exactly where in between 0.85 and 3.5 his passing output would finalize. That’s where Bayesian inference can help us.\n",
    "\n",
    "### Poisson Distributions\n",
    "Poisson distributions are ideal for our touchdown prop estimation. If you are unfamiliar with them, you can think of them as a good and simple way to model counts over a fixed period of time. For example, let’s say I drink around 0.86 coffees per day. The Poisson distribution for my coffee intake per day could be modeled by a Poisson distribution with mean 0.86. Unlike Normal distributions, I don’t need to know the standard deviation or any other parameter. The variance is equal to the mean.\n",
    "\n",
    "https://towardsdatascience.com/create-your-own-nfl-touchdown-props-with-python-b3896f19a588\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ec1d4-604d-490b-9f9b-38921a5d7ed7",
   "metadata": {},
   "source": [
    "### https://www.reddit.com/r/algobetting/comments/1di9jvh/which_machine_learning_model_for_my_use_case/\n",
    "\n",
    "No papers or anything I'd suggest, but fundamentally what you want to end up with is the probability you win your bet, that's what your target needs to be and what the model needs to output. So if your bet is on event A happening, then your model needs to be able to produce a probability for event A happening.\n",
    "\n",
    "if your bet is on event A happening, then your model needs to be able to produce a probability for event A happening\n",
    "\n",
    "u/playful_match_9556 This is the key. Took me a bit to figure out but projecting accurate probabilities is the best thing you can do, then find lines where you're +EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb198e6f-82e3-4164-9df4-b8891aa7ba28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd2337b-2687-4404-bd07-b602f6c26160",
   "metadata": {},
   "source": [
    "### Example Process for Estimating Player Data (w/o Bayesian/Poisson):\n",
    "Let’s walk through how you might estimate these inputs:\n",
    "\n",
    "1. **CARRIES**: Look at the player’s average carries over the past 5 games, adjust for the opponent’s run defense strength.\n",
    "   - **Estimate**: 10 carries.\n",
    "\n",
    "2. **RUSHING YARDS**: Combine the player’s average yards per carry with the estimated number of carries and adjust for the opponent's defensive strength.\n",
    "   - **Estimate**: 50 yards.\n",
    "\n",
    "3. **RECEPTIONS**: Consider the player’s recent targets, their role in the passing game, and how often the opposing defense allows receptions to similar players.\n",
    "   - **Estimate**: 3 receptions.\n",
    "\n",
    "4. **TARGETS**: Look at the player’s target share in recent games and adjust based on expected game flow.\n",
    "   - **Estimate**: 5 targets.\n",
    "\n",
    "5. **RECEIVING YARDS**: Use the player’s average yards per reception, multiplied by the estimated number of receptions.\n",
    "   - **Estimate**: 25 yards.\n",
    "\n",
    "### Automating the Estimation Process:\n",
    "If you have historical data, you can create a simple function or model to automate these estimates. For example:\n",
    "\n",
    "```python\n",
    "def estimate_player_stats(player_id, opponent_id, recent_games=5):\n",
    "    # Calculate averages over the last `recent_games` games\n",
    "    carries = df[(df['player_id'] == player_id) & (df['opponent_id'] == opponent_id)].tail(recent_games)['carries'].mean()\n",
    "    rushing_yards = df[(df['player_id'] == player_id) & (df['opponent_id'] == opponent_id)].tail(recent_games)['rushing_yards'].mean()\n",
    "    receptions = df[(df['player_id'] == player_id) & (df['opponent_id'] == opponent_id)].tail(recent_games)['receptions'].mean()\n",
    "    targets = df[(df['player_id'] == player_id) & (df['opponent_id'] == opponent_id)].tail(recent_games)['targets'].mean()\n",
    "    receiving_yards = df[(df['player_id'] == player_id) & (df['opponent_id'] == opponent_id)].tail(recent_games)['receiving_yards'].mean()\n",
    "\n",
    "    return {\n",
    "        'carries': carries,\n",
    "        'rushing_yards': rushing_yards,\n",
    "        'receptions': receptions,\n",
    "        'targets': targets,\n",
    "        'receiving_yards': receiving_yards\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "player_data = estimate_player_stats(player_id=123, opponent_id=456)\n",
    "```\n",
    "\n",
    "### Final Prediction:\n",
    "Once you have estimated these values, you can use them as inputs to your trained model:\n",
    "\n",
    "```python\n",
    "player_df = pd.DataFrame(player_data, index=[0])  # Ensure it's in the correct format\n",
    "touchdown_probability = xgb_model.predict_proba(player_df)[:, 1]\n",
    "print(f\"Probability of the player scoring a touchdown: {touchdown_probability[0]:.4f}\")\n",
    "```\n",
    "\n",
    "This process allows you to generate reasonable estimates for the inputs, enabling the model to provide predictions even when actual game data isn’t available yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05058b0-bcf0-4605-98e0-e9ff15e41722",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb170f-b6f8-48cb-b80d-cc7a86c00728",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bd763-0901-4702-8453-1a65ad4010e2",
   "metadata": {},
   "source": [
    "***Creating your target and performing a train-test split should always be your first two steps, no matter what kind of machine learning model you may be running.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b37f58-4fe6-4dae-a737-5e382d3379e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT team_name, SUM(touchdowns_allowed) AS total_touchdowns_allowed, SUM(yards_allowed) AS total_yards_allowed\nFROM TeamStats\nGROUP BY team_name\n': no such table: TeamStats",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: TeamStats",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m conn = sqlite3.connect(\u001b[33m'\u001b[39m\u001b[33mnfl.db\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mSELECT team_name, SUM(touchdowns_allowed) AS total_touchdowns_allowed, SUM(yards_allowed) AS total_yards_allowed\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mFROM TeamStats\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mGROUP BY team_name\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m team_defense_stats = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m conn.close()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Step 2: Calculate Defense Strength\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mread_query\u001b[39m(\n\u001b[32m   2728\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2729\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2736\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2737\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2738\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2739\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2683\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2685\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\nSELECT team_name, SUM(touchdowns_allowed) AS total_touchdowns_allowed, SUM(yards_allowed) AS total_yards_allowed\nFROM TeamStats\nGROUP BY team_name\n': no such table: TeamStats"
     ]
    }
   ],
   "source": [
    "# Create defense power rankings\n",
    "\n",
    "# Step 1: Extract Data from the Database\n",
    "conn = sqlite3.connect('nfl.db')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT team_name, SUM(touchdowns_allowed) AS total_touchdowns_allowed, SUM(yards_allowed) AS total_yards_allowed\n",
    "FROM TeamStats\n",
    "GROUP BY team_name\n",
    "\"\"\"\n",
    "\n",
    "team_defense_stats = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Step 2: Calculate Defense Strength\n",
    "team_defense_stats['defense_strength'] = (\n",
    "    0.5 * team_defense_stats['total_touchdowns_allowed'] +\n",
    "    0.5 * team_defense_stats['total_yards_allowed']\n",
    ")\n",
    "\n",
    "# Step 3: Normalize Defense Strength\n",
    "team_defense_stats['defense_strength'] = (\n",
    "    (team_defense_stats['defense_strength'] - team_defense_stats['defense_strength'].min()) /\n",
    "    (team_defense_stats['defense_strength'].max() - team_defense_stats['defense_strength'].min())\n",
    ")\n",
    "\n",
    "# Invert the scale so that lower values indicate stronger defense\n",
    "team_defense_stats['defense_strength'] = 1 - team_defense_stats['defense_strength']\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "output_df = team_defense_stats[['team_name', 'defense_strength']]\n",
    "output_df.to_csv('defense_strength.csv', index=False)\n",
    "\n",
    "print(\"Opponent defense strength values saved to 'defense_strength.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b5b570-ffff-4120-ac36-78f5f6f66fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['player', 'player_id', 'team', 'pass_cmp', 'pass_att', 'pass_yds', 'pass_td', 'pass_int', 'pass_sacked', 'pass_sacked_yds', 'pass_long', 'pass_rating', 'rush_att', 'rush_yds', 'rush_td', 'rush_long', 'targets', 'rec', 'rec_yds', 'rec_td', 'rec_long', 'fumbles', 'fumbles_lost', 'game_id', 'opponent_team', 'home', 'position']\n",
      "Opponent defense strength values saved to 'defense_strength.csv'\n"
     ]
    }
   ],
   "source": [
    "#v2 w/ weights\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the seasons you want to include (e.g., 2021, 2022, 2023)\n",
    "seasons = [2021, 2022, 2023]\n",
    "\n",
    "# Load PlayerStats from CSV\n",
    "player_stats_df = pd.read_csv('PlayerStats.csv')\n",
    "\n",
    "# Use all data for defense calculation (no season column in this dataset)\n",
    "print(\"Available columns:\", player_stats_df.columns.tolist())\n",
    "filtered_df = player_stats_df.copy()\n",
    "\n",
    "# Calculate team defense stats using actual column names\n",
    "team_defense_stats = filtered_df.groupby('opponent_team').agg({\n",
    "    'rush_td': 'sum',\n",
    "    'pass_td': 'sum', \n",
    "    'rec_td': 'sum',\n",
    "    'rush_yds': 'sum',\n",
    "    'rec_yds': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate total touchdowns and yards allowed\n",
    "team_defense_stats['total_touchdowns_allowed'] = team_defense_stats['rush_td'] + team_defense_stats['pass_td'] + team_defense_stats['rec_td']\n",
    "team_defense_stats['total_yards_allowed'] = team_defense_stats['rush_yds'] + team_defense_stats['rec_yds']\n",
    "\n",
    "# Keep only needed columns and rename for consistency\n",
    "team_defense_stats = team_defense_stats[['opponent_team', 'total_touchdowns_allowed', 'total_yards_allowed']].rename(columns={'opponent_team': 'team_name'})\n",
    "\n",
    "# Step 2: Weight and Normalize Metrics\n",
    "\n",
    "# Assign weights to touchdowns and yards allowed\n",
    "weights = {\n",
    "    'total_touchdowns_allowed': 0.5,\n",
    "    'total_yards_allowed': 0.5\n",
    "}\n",
    "\n",
    "# Calculate a composite defensive strength index\n",
    "team_defense_stats['composite_defense_strength'] = (\n",
    "    weights['total_touchdowns_allowed'] * team_defense_stats['total_touchdowns_allowed'] +\n",
    "    weights['total_yards_allowed'] * team_defense_stats['total_yards_allowed']\n",
    ")\n",
    "\n",
    "# Normalize the composite score (min-max normalization)\n",
    "team_defense_stats['defense_strength'] = (\n",
    "    (team_defense_stats['composite_defense_strength'] - team_defense_stats['composite_defense_strength'].min()) /\n",
    "    (team_defense_stats['composite_defense_strength'].max() - team_defense_stats['composite_defense_strength'].min())\n",
    ")\n",
    "\n",
    "# Invert so that lower scores indicate stronger defenses\n",
    "team_defense_stats['defense_strength'] = 1 - team_defense_stats['defense_strength']\n",
    "\n",
    "# Step 3: Save to CSV\n",
    "output_df = team_defense_stats[['team_name', 'defense_strength']]\n",
    "output_df.to_csv('defense_strength.csv', index=False)\n",
    "\n",
    "print(\"Opponent defense strength values saved to 'defense_strength.csv'\")\n",
    "\n",
    "# Optionally, open the file\n",
    "# !open defense_strength.csv\n",
    "\n",
    "!open defense_strength.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f82722-ebe1-406b-93f4-a47a623989db",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'away_team'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'away_team'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m defense_strength_df = pd.read_csv(defense_strength_path)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Create the 'opponent_team' column directly using a vectorized approach\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m player_stats_df[\u001b[33m'\u001b[39m\u001b[33mopponent_team\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mplayer_stats_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_team\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.where(\n\u001b[32m     16\u001b[39m     player_stats_df[\u001b[33m'\u001b[39m\u001b[33mrecent_team\u001b[39m\u001b[33m'\u001b[39m] == player_stats_df[\u001b[33m'\u001b[39m\u001b[33mhome_team\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     17\u001b[39m     player_stats_df[\u001b[33m'\u001b[39m\u001b[33mhome_team\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Merge the player_stats_df with the defense strengths based on the opponent_team\u001b[39;00m\n\u001b[32m     21\u001b[39m player_stats_df = pd.merge(\n\u001b[32m     22\u001b[39m     player_stats_df,\n\u001b[32m     23\u001b[39m     defense_strength_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     right_on=\u001b[33m'\u001b[39m\u001b[33mteam_name\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'away_team'"
     ]
    }
   ],
   "source": [
    "# Merge opponent defense strength to PlayerStats.csv table \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to CSV files\n",
    "defense_strength_path = 'defense_strength.csv'\n",
    "player_stats_path = 'PlayerStats.csv'\n",
    "output_path = 'PlayerStats.csv'\n",
    "\n",
    "# Load the CSV files\n",
    "player_stats_df = pd.read_csv(player_stats_path)\n",
    "defense_strength_df = pd.read_csv(defense_strength_path)\n",
    "\n",
    "# Create the 'opponent_team' column directly using a vectorized approach\n",
    "player_stats_df['opponent_team'] = player_stats_df['away_team'].where(\n",
    "    player_stats_df['recent_team'] == player_stats_df['home_team'], \n",
    "    player_stats_df['home_team']\n",
    ")\n",
    "\n",
    "# Merge the player_stats_df with the defense strengths based on the opponent_team\n",
    "player_stats_df = pd.merge(\n",
    "    player_stats_df,\n",
    "    defense_strength_df,\n",
    "    how='left',\n",
    "    left_on='opponent_team',\n",
    "    right_on='team_name'\n",
    ")\n",
    "\n",
    "# Rename the defense strength column for clarity\n",
    "player_stats_df.rename(columns={'defense_strength': 'opponent_defense_strength'}, inplace=True)\n",
    "\n",
    "# Drop the extra column after merging\n",
    "columns_to_drop = ['team_name']\n",
    "player_stats_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "player_stats_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Optionally, display the first few rows to verify\n",
    "print(player_stats_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c904147-195e-4350-9e0c-1cff410e8aac",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fc443-49ea-463f-8912-1946e85024dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV and filter for skill positions\n",
    "\n",
    "df = pd.read_csv('PlayerStats.csv')\n",
    "df = df[df['position'].isin(['RB', 'WR', 'TE'])]\n",
    "print(f\"Loaded {len(df)} records for RB, WR, TE players\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf96332-1d8f-4d14-9362-4ef39c0e286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable using actual column names\n",
    "# Combine rush_td and rec_td to create a binary outcome scored_touchdown (1 if the player scored a touchdown, 0 if not)\n",
    "\n",
    "df['scored_touchdown'] = ((df['rush_td'] > 0) | (df['rec_td'] > 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33223cf-519b-4f10-bdc5-19febe0f99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features including opponent defense strength\n",
    "features = ['rush_att', 'rush_yds', 'rec', 'targets', 'rec_yds', 'opponent_defense_strength']\n",
    "X = df[features].fillna(0)  # Fill NaN values with 0\n",
    "y = df['scored_touchdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b408c-9e6d-4536-ac9b-51b491b557d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd9a5a-be97-48ec-9605-f248436cc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "# xgb_model = xgb.XGBClassifier(eval_metric='logloss', n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2bd9-1608-496a-8d72-37b0f62a2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb859d8e-aa8b-4e15-a311-460ca4de9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e64db-049a-4597-983a-c0f90e11889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10c9ac-0605-482c-b64d-ec6fe0339b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Importance\n",
    "# XGBoost provides a way to access the importance of each feature in the model, which tells you how much each feature \n",
    "# contributes to the prediction.import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(xgb_model)\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, you can print the feature importance scores directly\n",
    "feature_importance = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in feature_importance.items():\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28566ba-345e-4faf-b40f-4c04c376826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Confusion Matrix\n",
    "# A confusion matrix gives you a detailed breakdown of correct and incorrect predictions. It helps you understand where\n",
    "# the model is making mistakes.\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate a detailed classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025211f1-df28-4d4e-822c-522dda6e0f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logloss Value\n",
    "# To see the logloss value, which is the evaluation metric you've used, you can print the evaluation results during training.\n",
    "\n",
    "# Initialize the model with eval_metric as a parameter\n",
    "xgb_model = xgb.XGBClassifier(eval_metric=\"logloss\")\n",
    "\n",
    "# Define the evaluation set\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "# Train the model with evaluation monitoring\n",
    "xgb_model.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "\n",
    "# After training, you can access the evaluation results\n",
    "evals_result = xgb_model.evals_result()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58dc9b-745c-46ea-b330-4a85e43b4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust params ^\n",
    "\n",
    "# Initialize the model with adjusted parameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    # n_estimators=200,  # More boosting rounds\n",
    "    # learning_rate=0.05,  # Smaller learning rate for better performance\n",
    "    max_depth=4,  # Depth of the trees\n",
    "    # subsample=0.8,  # Subsampling to reduce overfitting\n",
    "    # colsample_bytree=0.8  # Feature subsampling\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model as before\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4974d-aeb7-49c5-b98a-21e27d5c5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together w/ Bayesian Inteference\n",
    "\n",
    "def predict_touchdown_probability(player_name, opponent_defense_strength):\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect('nfl.db')\n",
    "\n",
    "    # Query to get historical data for the specific player using the correct column name\n",
    "    query = f\"\"\"\n",
    "    SELECT carries, rushing_yards, receptions, targets, receiving_yards\n",
    "    FROM PlayerStats\n",
    "    WHERE player_display_name = '{player_name}'\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the data into a DataFrame\n",
    "    historical_data = pd.read_sql_query(query, conn)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    # Calculate prior distributions based on historical data\n",
    "    carries_prior_mean = historical_data['carries'].mean()\n",
    "    carries_prior_std = historical_data['carries'].std()\n",
    "\n",
    "    rushing_yards_prior_mean = historical_data['rushing_yards'].mean()\n",
    "    rushing_yards_prior_std = historical_data['rushing_yards'].std()\n",
    "\n",
    "    receptions_prior_mean = historical_data['receptions'].mean()\n",
    "    receptions_prior_std = historical_data['receptions'].std()\n",
    "\n",
    "    targets_prior_mean = historical_data['targets'].mean()\n",
    "    targets_prior_std = historical_data['targets'].std()\n",
    "\n",
    "    receiving_yards_prior_mean = historical_data['receiving_yards'].mean()\n",
    "    receiving_yards_prior_std = historical_data['receiving_yards'].std()\n",
    "\n",
    "    # Create prior distributions\n",
    "    carries_prior = norm(loc=carries_prior_mean, scale=carries_prior_std)\n",
    "    rushing_yards_prior = norm(loc=rushing_yards_prior_mean, scale=rushing_yards_prior_std)\n",
    "    receptions_prior = norm(loc=receptions_prior_mean, scale=receptions_prior_std)\n",
    "    targets_prior = norm(loc=targets_prior_mean, scale=targets_prior_std)\n",
    "    receiving_yards_prior = norm(loc=receiving_yards_prior_mean, scale=receiving_yards_prior_std)\n",
    "\n",
    "    # Adjust the means based on the opponent's defense strength\n",
    "    carries_likelihood_mean = carries_prior_mean * opponent_defense_strength\n",
    "    rushing_yards_likelihood_mean = rushing_yards_prior_mean * opponent_defense_strength\n",
    "    receptions_likelihood_mean = receptions_prior_mean * opponent_defense_strength\n",
    "    targets_likelihood_mean = targets_prior_mean * opponent_defense_strength\n",
    "    receiving_yards_likelihood_mean = receiving_yards_prior_mean * opponent_defense_strength\n",
    "\n",
    "    # Combine prior and likelihood to get posterior estimates\n",
    "    carries_posterior = (carries_prior.mean() + carries_likelihood_mean) / 2\n",
    "    rushing_yards_posterior = (rushing_yards_prior.mean() + rushing_yards_likelihood_mean) / 2\n",
    "    receptions_posterior = (receptions_prior.mean() + receptions_likelihood_mean) / 2\n",
    "    targets_posterior = (targets_prior.mean() + targets_likelihood_mean) / 2\n",
    "    receiving_yards_posterior = (receiving_yards_prior.mean() + receiving_yards_likelihood_mean) / 2\n",
    "\n",
    "    # Create the player data based on the posterior estimates\n",
    "    player_data = {\n",
    "        'carries': [carries_posterior],\n",
    "        'rushing_yards': [rushing_yards_posterior],\n",
    "        'receptions': [receptions_posterior],\n",
    "        'targets': [targets_posterior],\n",
    "        'receiving_yards': [receiving_yards_posterior]\n",
    "    }\n",
    "\n",
    "    # Convert this data to a DataFrame\n",
    "    player_df = pd.DataFrame(player_data)\n",
    "\n",
    "    # Use the trained model to predict the probability of scoring a touchdown\n",
    "    touchdown_probability = xgb_model.predict_proba(player_df)[:, 1]  # Probability of class 1 (scored a touchdown)\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Probability of {player_name} scoring a touchdown: {touchdown_probability[0]:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "# predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=0) # lower opponent_defense_strength better defense\n",
    "# predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=1) # lower opponent_defense_strength better defense\n",
    "predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=0.6) # lower opponent_defense_strength better defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b96a47-b98a-48e5-aa45-ddf673656bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc933bd-71f5-4ce7-ad74-a3031073cfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e95b3a21-c8d3-429e-a774-c66836afdb00",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec75e3-1a33-415a-b05d-be0d8b0ac199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "conn = sqlite3.connect('nfl.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM PlayerStats WHERE position IN ('RB', 'WR', 'TE');\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Combine rushing_tds and receiving_tds to create a binary outcome scored_touchdown (1 if the player scored a touchdown, 0 if not)\n",
    "df['scored_touchdown'] = df[['rushing_tds', 'receiving_tds']].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "features = ['carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards']\n",
    "X = df[features]\n",
    "y = df['scored_touchdown']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6298e71-f959-405a-8c7c-3641bd1ce7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w opponent defense\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load player data from the CSV file\n",
    "df = pd.read_csv('PlayerStats.csv')\n",
    "\n",
    "# Combine rushing_tds and receiving_tds to create a binary outcome scored_touchdown (1 if the player scored a touchdown, 0 if not)\n",
    "df['scored_touchdown'] = df[['rushing_tds', 'receiving_tds']].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Select features including opponent defense strength\n",
    "features = ['carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'opponent_defense_strength']\n",
    "X = df[features]\n",
    "y = df['scored_touchdown']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to predict touchdown probability\n",
    "def predict_touchdown_probability(player_name, opponent_defense_strength):\n",
    "    # Query the player's data from the CSV file\n",
    "    player_data = df[df['player_display_name'] == player_name].copy()\n",
    "\n",
    "    if player_data.empty:\n",
    "        raise ValueError(f\"No data found for player: {player_name}\")\n",
    "\n",
    "    # Add the provided opponent defense strength to the player's data\n",
    "    player_data.loc[:, 'opponent_defense_strength'] = opponent_defense_strength\n",
    "\n",
    "    # Prepare the data for prediction\n",
    "    X_player = player_data[features]\n",
    "\n",
    "    # Use the model to predict the probability\n",
    "    probability = rf_model.predict_proba(X_player)[:, 1]  # Probability of scoring a touchdown\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Probability of {player_name} scoring a touchdown against an opponent with defense strength {opponent_defense_strength}: {probability[0]:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55267e96-1859-43f3-88f0-4b477fc8ccec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c38c1493-6fbe-46b8-a929-cdf466889483",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c702125-917e-433a-9cfd-a959e4add311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/o opponent defense\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Connect to the database and load data\n",
    "conn = sqlite3.connect('nfl.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM PlayerStats WHERE position IN ('RB', 'WR', 'TE');\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Create the target variable\n",
    "df['scored_touchdown'] = df[['rushing_tds', 'receiving_tds']].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Select features\n",
    "features = ['carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards']\n",
    "X = df[features]\n",
    "y = df['scored_touchdown']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to predict touchdown probability\n",
    "def predict_touchdown_probability(player_name, opponent_defense_strength):\n",
    "    # Query the player's data from the database\n",
    "    conn = sqlite3.connect('nfl.db')\n",
    "    query = f\"\"\"\n",
    "    SELECT carries, rushing_yards, receptions, targets, receiving_yards\n",
    "    FROM PlayerStats\n",
    "    WHERE player_display_name = '{player_name}'\n",
    "    \"\"\"\n",
    "    player_data = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    if player_data.empty:\n",
    "        raise ValueError(f\"No data found for player: {player_name}\")\n",
    "\n",
    "    # Use the model to predict the probability\n",
    "    X_player = player_data[features]\n",
    "    probability = logreg_model.predict_proba(X_player)[:, 1]  # Probability of scoring a touchdown\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Probability of {player_name} scoring a touchdown: {probability[0]:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea6837-42bb-4abf-9536-5d017f1bf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w opponent defense\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Connect to the database and load data\n",
    "# conn = sqlite3.connect('nfl.db')\n",
    "# df = pd.read_sql_query(\"SELECT * FROM PlayerStats WHERE position IN ('RB', 'WR', 'TE');\", conn)\n",
    "# conn.close()\n",
    "df = pd.read_csv('PlayerStats.csv')\n",
    "\n",
    "# Create the target variable\n",
    "df['scored_touchdown'] = df[['rushing_tds', 'receiving_tds']].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Select features including opponent defense strength\n",
    "features = ['carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'opponent_defense_strength']\n",
    "X = df[features]\n",
    "y = df['scored_touchdown']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to predict touchdown probability\n",
    "def predict_touchdown_probability(player_name, opponent_defense_strength):\n",
    "    # Query the player's data from the CSV file\n",
    "    player_data = df[df['player_display_name'] == player_name].copy()\n",
    "\n",
    "    if player_data.empty:\n",
    "        raise ValueError(f\"No data found for player: {player_name}\")\n",
    "\n",
    "    # Add the provided opponent defense strength to the player's data\n",
    "    player_data.loc[:, 'opponent_defense_strength'] = opponent_defense_strength\n",
    "\n",
    "    # Prepare the data for prediction\n",
    "    X_player = player_data[features]\n",
    "\n",
    "    # Use the model to predict the probability\n",
    "    probability = logreg_model.predict_proba(X_player)[:, 1]  # Probability of scoring a touchdown\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Probability of {player_name} scoring a touchdown against an opponent with defense strength {opponent_defense_strength}: {probability[0]:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "predict_touchdown_probability(player_name=\"Travis Kelce\", opponent_defense_strength=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b053e-ec9e-4254-b37b-d6a886eea6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35420e8-f942-4149-b3dc-286dc629fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6a285-efb3-403e-8d26-7e911ee83926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c01a5-c0b4-4573-87ad-ce833f4d89df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b95f9c-9ee4-402f-9306-76db2077fe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2025 Season Touchdown Predictions ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Example predictions for 2025 season\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== 2025 Season Touchdown Predictions ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mpredict_2025_touchdown\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTravis Kelce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBUF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimated_receptions\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimated_targets\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimated_receiving_yards\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mpredict_2025_touchdown\u001b[39m\u001b[34m(player_name, opponent_team, opponent_defense_strength, estimated_carries, estimated_rushing_yards, estimated_receptions, estimated_targets, estimated_receiving_yards)\u001b[39m\n\u001b[32m     17\u001b[39m player_df = pd.DataFrame([player_data])\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Get prediction from XGBoost model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m xgb_prob = \u001b[43mxgb_model\u001b[49m.predict_proba(player_df)[:, \u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTouchdown Prediction for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopponent_team\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_prob\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_prob*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xgb_prob\n",
      "\u001b[31mNameError\u001b[39m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict for an upcoming 2025 game\n",
    "\n",
    "def predict_2025_touchdown(player_name, opponent_team, opponent_defense_strength, \n",
    "                          estimated_carries=0, estimated_rushing_yards=0, \n",
    "                          estimated_receptions=3, estimated_targets=5, estimated_receiving_yards=25):\n",
    "    \n",
    "    # Create prediction data\n",
    "    player_data = {\n",
    "        'carries': estimated_carries,\n",
    "        'rushing_yards': estimated_rushing_yards,\n",
    "        'receptions': estimated_receptions,\n",
    "        'targets': estimated_targets,\n",
    "        'receiving_yards': estimated_receiving_yards,\n",
    "        'opponent_defense_strength': opponent_defense_strength\n",
    "    }\n",
    "    \n",
    "    player_df = pd.DataFrame([player_data])\n",
    "    \n",
    "    # Get prediction from XGBoost model\n",
    "    xgb_prob = xgb_model.predict_proba(player_df)[:, 1][0]\n",
    "    \n",
    "    print(f\"Touchdown Prediction for {player_name} vs {opponent_team}: {xgb_prob:.4f} ({xgb_prob*100:.1f}%)\")\n",
    "    \n",
    "    return xgb_prob\n",
    "\n",
    "# Example predictions for 2025 season\n",
    "print(\"=== 2025 Season Touchdown Predictions ===\")\n",
    "predict_2025_touchdown(\"Travis Kelce\", \"BUF\", 0.3, estimated_receptions=4, estimated_targets=6, estimated_receiving_yards=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017d128-ebc0-4594-b6c3-e9e4bdf55b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
