{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd7e34d-9016-4605-925c-9f840bd8a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ce8fca-2498-4cf6-94f3-63b985f45a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data\n",
    "!cp -r ../Scrapers/data .\n",
    "!cp ../Scrapers/nfl.db data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814dde27-9781-44ca-9fe7-6a1f9c27832e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21eeb6a7-5add-46a2-a0ff-214bf64613c8",
   "metadata": {},
   "source": [
    "# BETTING TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20f676-f835-488e-868f-718f4ce30790",
   "metadata": {},
   "source": [
    "## Performance as Favorite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25997fad-81cc-47bc-a798-bde4a67657da",
   "metadata": {},
   "source": [
    "## Performance as Underdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bbd925-989f-4c3f-b36d-52722ababf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All teams seasons data saved to nfl_game_summaries.csv\n",
      "\n",
      "\n",
      "------------------------------------------ BAL Underdog Results 2021-2023 ------------------------------------------\n",
      "2021:\n",
      "Week 02: BAL @ KC, spread: 3.5 (KC favored), result: BAL WIN 36.0-35.0, STRAIGHT-UP: WIN, ATS: LOSE, ATS Diff: -2.5\n",
      "Week 04: BAL @ DEN, spread: 1.0 (DEN favored), result: BAL WIN 23.0-7.0, STRAIGHT-UP: WIN, ATS: WIN, ATS Diff: +17.0\n",
      "Week 14: BAL @ CLE, spread: 3.0 (CLE favored), result: BAL LOSE 22.0-24.0, STRAIGHT-UP: LOSE, ATS: WIN, ATS Diff: +1.0\n",
      "Week 15: BAL @ GB, spread: 9.5 (GB favored), result: BAL LOSE 30.0-31.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -10.5\n",
      "Week 16: BAL @ CIN, spread: 7.5 (CIN favored), result: BAL LOSE 21.0-41.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -12.5\n",
      "Week 17: BAL @ LAR, spread: 7.0 (LAR favored), result: BAL LOSE 19.0-20.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -8.0\n",
      "\n",
      "2022:\n",
      "Week 04: BAL @ BUF, spread: 3.0 (BUF favored), result: BAL LOSE 20.0-23.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -6.0\n",
      "Week 08: BAL @ TB, spread: 2.0 (TB favored), result: BAL WIN 27.0-22.0, STRAIGHT-UP: WIN, ATS: WIN, ATS Diff: +7.0\n",
      "Week 14: BAL @ PIT, spread: 1.5 (PIT favored), result: BAL WIN 16.0-14.0, STRAIGHT-UP: WIN, ATS: WIN, ATS Diff: +3.5\n",
      "Week 15: BAL @ CLE, spread: 2.5 (CLE favored), result: BAL LOSE 3.0-13.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -7.5\n",
      "Week 18: BAL @ CIN, spread: 11.0 (CIN favored), result: BAL LOSE 16.0-27.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: +0.0\n",
      "Week 19: BAL @ CIN, spread: 7.5 (CIN favored), result: BAL LOSE 17.0-24.0, STRAIGHT-UP: LOSE, ATS: WIN, ATS Diff: +0.5\n",
      "\n",
      "2023:\n",
      "Week 02: BAL @ CIN, spread: 3.5 (CIN favored), result: BAL WIN 27.0-24.0, STRAIGHT-UP: WIN, ATS: WIN, ATS Diff: +6.5\n",
      "Week 16: BAL @ SF, spread: 6.5 (SF favored), result: BAL WIN 33.0-19.0, STRAIGHT-UP: WIN, ATS: WIN, ATS Diff: +20.5\n",
      "Week 18: BAL @ PIT, spread: 3.0 (PIT favored), result: BAL LOSE 10.0-17.0, STRAIGHT-UP: LOSE, ATS: LOSE, ATS Diff: -10.0\n",
      "\n",
      "\u001b[1mATS Record: 7-8\u001b[0m\n",
      "\u001b[1mStraight-up Record: 6-9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Loop all teams and saving to files ^\n",
    "\n",
    "# Function to get underdog games\n",
    "def get_underdog_games(team_name, seasons, db_path):\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Prepare a query to get all games for the given team where they were the underdog\n",
    "    query = f\"\"\"\n",
    "    SELECT season, week, away_team, home_team, spread_line, team_favorite, result, home_score, away_score \n",
    "    FROM Games\n",
    "    WHERE season IN ({','.join(map(str, seasons))})\n",
    "    AND (home_team = '{team_name}' OR away_team = '{team_name}')\n",
    "    AND team_favorite != '{team_name}';\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute query\n",
    "    games = conn.execute(query).fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    columns = ['season', 'week', 'away_team', 'home_team', 'spread_line', 'team_favorite', 'result', 'home_score', 'away_score']\n",
    "    games_df = pd.DataFrame(games, columns=columns)\n",
    "    \n",
    "    # Calculate the point differential and whether the team covered the spread\n",
    "    games_df['point_differential'] = games_df.apply(lambda row: row['away_score'] - row['home_score'] if row['away_team'] == team_name else row['home_score'] - row['away_score'], axis=1)\n",
    "    games_df['ats_differential'] = games_df.apply(lambda row: (row['point_differential'] + float(row['spread_line'])) if row['team_favorite'] != team_name else (row['point_differential'] - float(row['spread_line'])), axis=1)\n",
    "    games_df['spread_covered'] = games_df['ats_differential'] > 0\n",
    "    \n",
    "    return games_df\n",
    "\n",
    "# Function to summarize ATS record and return data for CSV\n",
    "def summarize_ats_record_for_csv(team_name, seasons, db_path):\n",
    "    underdog_games_df = get_underdog_games(team_name, seasons, db_path)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, game in underdog_games_df.iterrows():\n",
    "        # Construct the result as a dictionary for later CSV storage\n",
    "        result = {\n",
    "            'season': game['season'],\n",
    "            'week': game['week'],\n",
    "            'team': team_name,\n",
    "            'opponent': game['home_team'] if game['away_team'] == team_name else game['away_team'],\n",
    "            'team_score': game['away_score'] if game['away_team'] == team_name else game['home_score'],\n",
    "            'opponent_score': game['home_score'] if game['away_team'] == team_name else game['away_score'],\n",
    "            'spread': game['spread_line'],\n",
    "            'team_favorite': game['team_favorite'],\n",
    "            'ats_result': 'WIN' if game['spread_covered'] else 'LOSE',\n",
    "            'ats_differential': game['ats_differential'],\n",
    "            'straight_up_result': 'WIN' if game['point_differential'] > 0 else 'LOSE'\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to save the results for all teams into a CSV\n",
    "def save_all_teams_to_csv(teams, seasons, db_path, csv_file_path):\n",
    "    all_results = []\n",
    "    for team in teams:\n",
    "        team_results = summarize_ats_record_for_csv(team, seasons, db_path)\n",
    "        all_results.extend(team_results)  # Accumulate the results for all teams\n",
    "    \n",
    "    # Convert the list of results to a DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"All teams seasons data saved to {csv_file_path}\\n\\n\")\n",
    "\n",
    "# Example usage\n",
    "db_path = 'data/nfl.db'  # Update this with the correct path to your database file\n",
    "teams = [\n",
    "    'ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE',\n",
    "    'DAL', 'DEN', 'DET', 'GB', 'HOU', 'IND', 'JAX', 'KC',\n",
    "    'LV', 'LAC', 'LAR', 'MIA', 'MIN', 'NE', 'NO', 'NYG',\n",
    "    'NYJ', 'PHI', 'PIT', 'SF', 'SEA', 'TB', 'TEN', 'WAS'\n",
    "]  # List of all NFL teams\n",
    "seasons = [2021, 2022, 2023]  # Specify the seasons you want to analyze\n",
    "csv_file_path = 'nfl_game_summaries.csv'  # Path to save the CSV file\n",
    "\n",
    "# Save the results to a CSV\n",
    "save_all_teams_to_csv(teams, seasons, db_path, csv_file_path)\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('nfl_game_summaries.csv')\n",
    "\n",
    "# Set the team name directly\n",
    "# team_name = \"DAL\"  # Replace with the desired team name\n",
    "team_name = \"BAL\"  # Replace with the desired team name\n",
    "print(f'------------------------------------------ {team_name} Underdog Results 2021-2023 ------------------------------------------')\n",
    "\n",
    "# Filter the data for the given team\n",
    "team_data = df[df['team'] == team_name].sort_values(by=['season', 'week'])\n",
    "\n",
    "# Variables to store win/loss counts\n",
    "ats_wins, ats_losses = 0, 0\n",
    "straight_up_wins, straight_up_losses = 0, 0\n",
    "\n",
    "current_season = None\n",
    "for _, row in team_data.iterrows():\n",
    "    # Check if the season has changed to print it\n",
    "    if row['season'] != current_season:\n",
    "        if current_season is not None:\n",
    "            print()  # Print a newline before starting a new season\n",
    "        current_season = row['season']\n",
    "        print(f\"{row['season']}:\")\n",
    "\n",
    "    # Determine if the team is home or away and format the spread\n",
    "    home_or_away = \"vs\" if row['team_favorite'] == team_name else \"@\"\n",
    "    spread_info = f\"{abs(row['spread'])} ({row['team_favorite']} favored)\" if row['spread'] > 0 else f\"{abs(row['spread'])} ({row['team_favorite']} favored)\"\n",
    "    \n",
    "    # Format the game result\n",
    "    result = f\"Week {str(row['week']).zfill(2)}: {row['team']} {home_or_away} {row['opponent']}, spread: {spread_info}, \"\n",
    "    score_result = f\"result: {row['team']} {row['straight_up_result'].upper()} {row['team_score']}-{row['opponent_score']}, \"\n",
    "    straight_up = f\"STRAIGHT-UP: {row['straight_up_result'].upper()}\"\n",
    "    ats = f\"ATS: {row['ats_result'].upper()}, ATS Diff: {row['ats_differential']:+.1f}\"\n",
    "\n",
    "    # Print the formatted result\n",
    "    print(f\"{result}{score_result}{straight_up}, {ats}\")\n",
    "\n",
    "    # Count wins and losses\n",
    "    if row['ats_result'].lower() == 'win':\n",
    "        ats_wins += 1\n",
    "    else:\n",
    "        ats_losses += 1\n",
    "\n",
    "    if row['straight_up_result'].lower() == 'win':\n",
    "        straight_up_wins += 1\n",
    "    else:\n",
    "        straight_up_losses += 1\n",
    "\n",
    "# Print final ATS and straight-up records\n",
    "print()\n",
    "print(f\"\\033[1mATS Record: {ats_wins}-{ats_losses}\\033[0m\")\n",
    "print(f\"\\033[1mStraight-up Record: {straight_up_wins}-{straight_up_losses}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd576c48-b477-4fac-8b72-012ff68fb934",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4d38c-6fc9-4217-be42-8bdec5852591",
   "metadata": {},
   "source": [
    "# TEAM TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad359e-08a1-44d7-8196-26d4d2af6f36",
   "metadata": {},
   "source": [
    "# Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a77754-ab2c-48cf-b7ee-c87e78c62d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop and rank all teams 2020-2024 seasons\n",
    "\n",
    "# Function to calculate total defensive yards allowed for a given team and season\n",
    "def calculate_team_total_yards_defensive_stats(team_abbreviation, season, data_df):\n",
    "    # Filter for the specified season by extracting the season from the 'game_id' column\n",
    "    data_df['season'] = data_df['game_id'].str.slice(0, 4).astype(int)\n",
    "\n",
    "    # # Filter the data for the specific season\n",
    "    # if season == 2024:\n",
    "    #     # For the current season, only consider games played so far\n",
    "    #     current_week = data_df[data_df['season'] == season]['game_id'].str.slice(5, 7).astype(int).max()  # Get the latest week\n",
    "    #     season_games = data_df[(data_df['season'] == season) & (data_df['game_id'].str.slice(5, 7).astype(int) <= current_week)]\n",
    "    # else:\n",
    "    #     season_games = data_df[data_df['season'] == season]\n",
    "    # Filter the data for the specific season\n",
    "    if season == 2024:\n",
    "        # Filter out unplayed games based on the key stats columns (assuming unplayed games have all zeros)\n",
    "        season_games = data_df[(data_df['season'] == season) &\n",
    "                               (data_df[['away_rush_yds', 'away_pass_yds', 'home_rush_yds', 'home_pass_yds']].sum(axis=1) > 0)]\n",
    "    else:\n",
    "        season_games = data_df[data_df['season'] == season]\n",
    "\n",
    "\n",
    "    # Initialize lists for away and home games\n",
    "    away_games = []\n",
    "    home_games = []\n",
    "\n",
    "    # Loop through each game and split game_id to determine home/away status\n",
    "    for index, row in season_games.iterrows():\n",
    "        game_id_parts = row['game_id'].split('_')\n",
    "        game_season, week, away_team, home_team = game_id_parts\n",
    "\n",
    "        # Convert the week to an integer to filter weeks 01-18\n",
    "        week_num = int(week)\n",
    "\n",
    "        if week_num > 18:\n",
    "            continue  # Skip postseason weeks\n",
    "\n",
    "        if away_team == team_abbreviation:\n",
    "            away_games.append(row)  # The team was the away team in this game\n",
    "        elif home_team == team_abbreviation:\n",
    "            home_games.append(row)  # The team was the home team in this game\n",
    "\n",
    "    # Convert lists to DataFrames for easier processing\n",
    "    away_games_df = pd.DataFrame(away_games)\n",
    "    home_games_df = pd.DataFrame(home_games)\n",
    "\n",
    "    # Convert lists to DataFrames for easier processing\n",
    "    away_games_df = pd.DataFrame(away_games)\n",
    "    home_games_df = pd.DataFrame(home_games)\n",
    "\n",
    "    if not away_games_df.empty and all(col in away_games_df for col in ['home_rush_yds', 'home_pass_yds']):\n",
    "        away_defense_stats = away_games_df[['home_rush_yds', 'home_pass_yds']].sum()\n",
    "    else:\n",
    "        away_defense_stats = pd.Series({'home_rush_yds': 0, 'home_pass_yds': 0})\n",
    "    \n",
    "    if not home_games_df.empty and all(col in home_games_df for col in ['away_rush_yds', 'away_pass_yds']):\n",
    "        home_defense_stats = home_games_df[['away_rush_yds', 'away_pass_yds']].sum()\n",
    "    else:\n",
    "        home_defense_stats = pd.Series({'away_rush_yds': 0, 'away_pass_yds': 0})\n",
    "\n",
    "    # # For home games, we want the stats from the \"away\" columns (opponent is away team)\n",
    "    # home_defense_stats = home_games_df[['away_rush_yds', 'away_pass_yds']].sum()\n",
    "\n",
    "    # # For away games, we want the stats from the \"home\" columns (opponent is home team)\n",
    "    # away_defense_stats = away_games_df[['home_rush_yds', 'home_pass_yds']].sum()\n",
    "\n",
    "    # Combine rushing and passing yards for all games\n",
    "    total_rush_yards_allowed = home_defense_stats['away_rush_yds'] + away_defense_stats['home_rush_yds']\n",
    "    total_pass_yards_allowed = home_defense_stats['away_pass_yds'] + away_defense_stats['home_pass_yds']\n",
    "\n",
    "    # Calculate total yards allowed (rushing + passing)\n",
    "    total_yards_allowed = total_rush_yards_allowed + total_pass_yards_allowed\n",
    "\n",
    "    # Number of games played by the team\n",
    "    num_games = len(home_games_df) + len(away_games_df)\n",
    "\n",
    "    # Calculate averages for total yards allowed\n",
    "    defensive_summary = {\n",
    "        \"avg_total_yards_allowed\": total_yards_allowed / num_games if num_games > 0 else 0,\n",
    "        \"avg_rush_yards_allowed\": total_rush_yards_allowed / num_games if num_games > 0 else 0,\n",
    "        \"avg_pass_yards_allowed\": total_pass_yards_allowed / num_games if num_games > 0 else 0,\n",
    "        \"season\": season\n",
    "    }\n",
    "\n",
    "    return defensive_summary\n",
    "\n",
    "# Load the dataset (assuming it's located in 'data/' folder)\n",
    "file_path = 'data/all_team_game_logs.csv'\n",
    "team_game_logs_df = pd.read_csv(file_path)\n",
    "\n",
    "# List of all team abbreviations\n",
    "teams = ['ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE', 'DAL', 'DEN', \n",
    "         'DET', 'GB', 'HOU', 'IND', 'JAX', 'KC', 'LAC', 'LAR', 'LVR', 'MIA', \n",
    "         'MIN', 'NE', 'NO', 'NYG', 'NYJ', 'PHI', 'PIT', 'SEA', 'SF', 'TB', 'TEN', 'WAS']\n",
    "\n",
    "# List to hold defensive stats for all teams\n",
    "defensive_stats_list = []\n",
    "\n",
    "# Loop through the seasons 2020 to 2023, and the played games in 2024\n",
    "for season in range(2020, 2025):\n",
    "    for team in teams:\n",
    "        stats = calculate_team_total_yards_defensive_stats(team, season, team_game_logs_df)\n",
    "        stats['team'] = team  # Add team abbreviation to the stats\n",
    "        defensive_stats_list.append(stats)\n",
    "\n",
    "# # Handle the 2024 season for only played games\n",
    "# for team in teams:\n",
    "#     stats = calculate_team_total_yards_defensive_stats(team, 2024, team_game_logs_df)\n",
    "#     stats['team'] = team  # Add team abbreviation to the stats\n",
    "#     defensive_stats_list.append(stats)\n",
    "\n",
    "# Create a DataFrame from the defensive stats list\n",
    "defensive_stats_df = pd.DataFrame(defensive_stats_list)\n",
    "\n",
    "# Insert 'team' column at the first position\n",
    "defensive_stats_df.insert(0, 'team', defensive_stats_df.pop('team'))\n",
    "\n",
    "# Sort the DataFrame by average total yards allowed in descending order\n",
    "sorted_defensive_stats_df = defensive_stats_df.sort_values(by='avg_pass_yards_allowed', ascending=False)\n",
    "# sorted_defensive_stats_df = defensive_stats_df.sort_values(by=['season'], ascending=[True])\n",
    "\n",
    "# Reset index and drop the old index\n",
    "sorted_defensive_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a new column for row numbers\n",
    "# sorted_defensive_stats_df.insert(0, 'No', sorted_defensive_stats_df.index + 1)\n",
    "\n",
    "# Save to CSV without an index\n",
    "sorted_defensive_stats_df.to_csv('data/team_defense_analysis_2020_2024.csv', index=False)\n",
    "\n",
    "# Display the sorted DataFrame using Tabulate\n",
    "# print(tabulate(sorted_defensive_stats_df, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Defensive stats for all teams have been saved to 'team_defense_analysis_2020_2024.csv'.\")\n",
    "\n",
    "# Read the saved CSV file\n",
    "final_df = pd.read_csv('data/team_defense_analysis_2020_2024.csv')\n",
    "\n",
    "# Filter the DataFrame to include only the 2024 season\n",
    "df_2024 = final_df[final_df['season'] == 2024].copy()\n",
    "\n",
    "# Reset index for the filtered DataFrame (optional, for cleaner display)\n",
    "df_2024.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a new 'No' column specific to the 2024 data (optional)\n",
    "# df_2024.insert(0, 'No', df_2024.index + 1)\n",
    "\n",
    "# Display only the 2024 DataFrame using Tabulate\n",
    "print('\\n                                               2024 STATS')\n",
    "print(tabulate(df_2024, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "# Print confirmation message\n",
    "# print(\"Defensive stats for all teams have been saved to 'team_defense_analysis_2020_2024.csv'.\")\n",
    "\n",
    "# Filter the DataFrame to include only the 2023 season\n",
    "df_2023 = final_df[final_df['season'] == 2023].copy()\n",
    "\n",
    "# Reset index for the filtered DataFrame (optional, for cleaner display)\n",
    "df_2023.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a new 'No' column specific to the 2024 data (optional)\n",
    "# df_2024.insert(0, 'No', df_2024.index + 1)\n",
    "\n",
    "# Display only the 2024 DataFrame using Tabulate\n",
    "print('\\n                                               2023 STATS')\n",
    "print(tabulate(df_2023, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "# Print confirmation message\n",
    "# print(\"Defensive stats for all teams have been saved to 'team_defense_analysis_2020_2024.csv'.\")\n",
    "\n",
    "# !open data/team_defense_analysis_2020_2024.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaa657-8dab-40a7-abd1-86bb708f242e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e112803a-3a44-4bd2-b44d-6ec5b8d46ad6",
   "metadata": {},
   "source": [
    "## Sacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433582e-11d7-4a28-9ee7-7274b1b6b7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sacks Given & Taken\n",
    "\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "\n",
    "file_path = 'data/all_team_game_logs.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "unplayed_games = df[\n",
    "    df['game_id'].str.contains('2024') &  # Check if 'game_id' contains \"2024\"\n",
    "    ((df['home_pts_off'].isnull() | (df['home_pts_off'] == 0)) &\n",
    "     (df['away_pts_off'].isnull() | (df['away_pts_off'] == 0)))\n",
    "]\n",
    "unplayed_game_ids = unplayed_games['game_id'].tolist()\n",
    "df = df[~df['game_id'].isin(unplayed_game_ids)]\n",
    "# df.to_csv('data/all_team_game_logs.csv', index=False)\n",
    "print(\"Unplayed games removed and updated CSV saved.\")\n",
    "\n",
    "# Extract year and week from 'game_id'\n",
    "df[['year', 'week', 'away_team', 'home_team']] = df['game_id'].str.split('_', expand=True).iloc[:, :4]\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['week'] = df['week'].astype(int)\n",
    "\n",
    "for year in years:\n",
    "    # Filter for the 2023 season and weeks <= 18\n",
    "    df_2023 = df[(df['year'] == year) & (df['week'] <= 18)]\n",
    "    \n",
    "    # Initialize a dictionary to track sacks made and sacks taken\n",
    "    sack_stats = {\n",
    "        'team': [],\n",
    "        'sacks_made': [],\n",
    "        'sacks_taken': []\n",
    "    }\n",
    "    \n",
    "    # List of all 32 NFL teams\n",
    "    teams = [\n",
    "        'ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE',\n",
    "        'DAL', 'DEN', 'DET', 'GB', 'HOU', 'IND', 'JAX', 'KC',\n",
    "        'LV', 'LAC', 'LAR', 'MIA', 'MIN', 'NE', 'NO', 'NYG',\n",
    "        'NYJ', 'PHI', 'PIT', 'SF', 'SEA', 'TB', 'TEN', 'WAS'\n",
    "    ]\n",
    "    \n",
    "    # Calculate the sacks made and sacks taken for each team\n",
    "    for team in teams:\n",
    "        # Sacks made by the team's defense (home and away games)\n",
    "        sacks_made = df_2023.loc[(df_2023['home_team'] == team), 'away_pass_sacked'].sum() + \\\n",
    "                     df_2023.loc[(df_2023['away_team'] == team), 'home_pass_sacked'].sum()\n",
    "        \n",
    "        # Sacks taken (against the team) - includes home and away games\n",
    "        sacks_taken = df_2023.loc[(df_2023['home_team'] == team), 'home_pass_sacked'].sum() + \\\n",
    "                      df_2023.loc[(df_2023['away_team'] == team), 'away_pass_sacked'].sum()\n",
    "        \n",
    "        # Store results\n",
    "        sack_stats['team'].append(team)\n",
    "        sack_stats['sacks_made'].append(sacks_made)\n",
    "        sack_stats['sacks_taken'].append(sacks_taken)\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    sack_stats_df = pd.DataFrame(sack_stats)\n",
    "    \n",
    "    # # Calculate average sacks made and taken (if needed by game or for total analysis)\n",
    "    sack_stats_df['average_sacks_made'] = sack_stats_df['sacks_made'] / len(df_2023['week'].unique())\n",
    "    sack_stats_df['average_sacks_taken'] = sack_stats_df['sacks_taken'] / len(df_2023['week'].unique())\n",
    "    \n",
    "    sacks_made_sorted = sack_stats_df[['team', 'sacks_made', 'average_sacks_made']].sort_values(by='sacks_made', ascending=False)\n",
    "    sacks_taken_sorted = sack_stats_df[['team', 'sacks_taken', 'average_sacks_taken']].sort_values(by='sacks_taken', ascending=False)\n",
    "    \n",
    "    # Use tabulate to print both tables\n",
    "    # print(\"Teams Sorted by Sacks Made:\")\n",
    "    # print(tabulate(sacks_made_sorted, headers='keys', tablefmt='grid'))\n",
    "    print(sacks_made_sorted)\n",
    "    sacks_made_sorted.to_csv(f'data/sacks_made_sorted_{year}.csv', index=False)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    # print(\"\\nTeams Sorted by Sacks Taken:\")\n",
    "    # print(tabulate(sacks_taken_sorted, headers='keys', tablefmt='grid'))\n",
    "    print(sacks_taken_sorted)\n",
    "    sacks_taken_sorted.to_csv(f'data/sacks_taken_sorted_{year}.csv', index=False)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0d936-934c-484b-b354-63bed6275936",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open data/sacks_taken_sorted_2024.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b43b3-f730-4d2d-b964-41b64b43818a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb556e-730e-47c2-be7c-57b1a2b40cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23109914-07e3-482f-a1d1-4f7e97b05a72",
   "metadata": {},
   "source": [
    "## Offense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c94c31-c5d2-4eab-b2c4-9d4a142e159d",
   "metadata": {},
   "source": [
    "### Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ffda8-2b02-4c30-a62d-22ab11211fa6",
   "metadata": {},
   "source": [
    "### Rushing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628f577-48e9-4ef2-8baa-843ee0e59a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d974743d-5966-4f90-a027-e7d95f154198",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f509d3-c7d9-4445-b97e-84f571ed29b6",
   "metadata": {},
   "source": [
    "### General\n",
    "- (Passing/Rushing ypg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dae4c-501c-47ed-a25d-a0edc1a7cdb5",
   "metadata": {},
   "source": [
    "### Sacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88b3ac-9568-45a4-ac74-44da49fa42c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b24559-8f31-4f59-b4f3-8d46ca180fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e626d1c1-e059-49de-b5f5-1dd471cce4e7",
   "metadata": {},
   "source": [
    "# PLAYER TRENDS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509673a-1fdd-4151-b1f6-0540c224b5d0",
   "metadata": {},
   "source": [
    "# Quarterbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50dc9b3-3750-4e88-b431-a5942a4547bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34f94d6b-4ea2-4682-9148-2fa48bb339b5",
   "metadata": {},
   "source": [
    "## Running Backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffd982-73b7-4333-86c9-c857b28242f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29b4700-b959-4217-9bbd-b439d8f0fa72",
   "metadata": {},
   "source": [
    "## Wide Receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49118b4-536d-472d-8cc0-57a6680120c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f24467b-ed92-4c3c-84b4-3c4e86badbff",
   "metadata": {},
   "source": [
    "## Tight Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78c004-b3b5-40c4-abcd-5bf3df67b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197f4fa-0359-48f1-b527-610f1667c1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e719d05-8c6c-44b2-b3dd-ed94597529ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3e426-3adc-4baf-8926-ea2e28f0da4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd49e19-6fb0-4b9f-9b23-1c4a785baabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68768aef-3a55-49e9-a773-5f3061096aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96885b9-63e6-4182-a25d-07b48e0592f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1c068-e02d-4026-a642-0545843d8880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59211d-fcd6-475a-a7ba-d5c6b8642ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d05e3e-7196-4697-b2db-2f1f8f197c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cfa7a-eb4d-4a32-a65a-e8935a89ffff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523f88e-e11c-4c33-aab6-84555b60f570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d7875-a7b2-4408-b86a-b3fbdaae2e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5fb08-8704-4ad5-9be8-75df0c6477bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb9261-1a66-4006-b291-bd68f78ecfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78f965-e8e4-4ca2-9781-a634e17158a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a635dcb-8233-4767-9fff-6227f873014a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a011181-936a-436d-90e5-7fcd0d9c7d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d4932-99e0-462e-a1af-b5b82478350f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2081f4-f24b-45f3-b0a2-494aac61898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eff972-227e-4017-8ec9-aade4ab45c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
